[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistics 1 and 2",
    "section": "",
    "text": "Overview\nThis course covers the basics of statistics and data analysis. The ability to extract insights from data is an essential skill for both academic and non-academic work, and “data literacy” is increasingly important in a world where data are collected about every aspect of our lives. After completing this course, you will be able to independently analyze data, interpret and report your findings, and assess the results of analyses performed by others, such as you might find in scientific articles.\nThis GitBook contains all relevant information about this course. It is assumed that every student reads it carefully. If you have any questions, first consult this GitBook, then ask a fellow student, and only if your question is still not answered, then contact the course coordinator.\nCommunication about the course occurs through Canvas (Login with your student ID and password)."
  },
  {
    "objectID": "index.html#course-overview",
    "href": "index.html#course-overview",
    "title": "Statistics 1 and 2",
    "section": "Course overview",
    "text": "Course overview\nThe course schedule is available on Osiris. For an overview of the content, see below:\n\nWarning: package 'DT' was built under R version 4.3.1"
  },
  {
    "objectID": "index.html#this-gitbook",
    "href": "index.html#this-gitbook",
    "title": "Statistics 1 and 2",
    "section": "This GitBook",
    "text": "This GitBook\nYou do not need a book for this course!\nAll essential information is contained within this GitBook:\n\nA summary of each week’s material\nYouTube lectures by me\nAdditional YouTube tutorials not by me\nFormative tests to test how prepared you are for the final exam\nTutorial exercises for the lab session"
  },
  {
    "objectID": "index.html#sec-software",
    "href": "index.html#sec-software",
    "title": "Statistics 1 and 2",
    "section": "Software",
    "text": "Software\nDuring lab sessions, you work on the exercises and your portfolio using the commercial SPSS software installed on university computers.\nIf you want to use your own computer instead, you might consider trying some free alternatives to SPSS:\n\nPSPP, which is designed to be nearly identical to SPSS with all the same basic functionality: https://www.gnu.org/software/pspp/pspp.html\n\nJASP, which is more modern, looks nicer and is very easy to use – but looks less similar to SPSS: https://jasp-stats.org/"
  },
  {
    "objectID": "index.html#learning-goals",
    "href": "index.html#learning-goals",
    "title": "Statistics 1 and 2",
    "section": "Learning goals",
    "text": "Learning goals\nAfter taking this course, students will be able to…\nAll majors\n\ncompute and interpret commonly used descriptive statistics such as the sample mean, the median, the mode, variance and standard deviation, the standard error, and the correlation coefficient.\nrecognize different probability distributions such as the normal distribution, and make computations for these probability distributions.\nexplain the essential aspects of null-hypothesis significance testing, including sampling distributions, Type I and Type II errors, one-tailed versus two-tailed testing, and statistical power.\napply different statistical tests such as the Z-test, the one sample t-test, the one way Between Subjects Analysis of Variance test, and statistical tests related to (multiple) linear regression analysis with continuous and categorical predictors; and clarify the statistical and/or methodological assumptions that apply to the techniques that are discussed in this course.\nexplain basic concepts in regression analysis, including: linear association, least-squares estimation, explained variance, Multiple R, multiple correlation, adjusted R-square, raw and standardized regression coefficients, model-comparison tests, predicted scores, residuals and the assumptions;\nchoose the appropriate analysis technique for answering a specific research problem from the range of techniques that are covered in the course.\nuse the software package SPSS to perform several statistical data analyses and be able to correctly interpret and report the output to an informed audience (e.g., Liberal arts students, researchers from the social sciences/business and economics/cognitive neuroscience).\ndraw valid conclusions from the results of empirical data analyses given specific research questions envisaged.\nMajor Business and Economics\n\napply statistical tests in the context of multiple linear regression models with interaction terms and logistic regression models; interpret the corresponding output.\ndescribe the concepts of probabilities, odds and logits; describe the relationship between the three scales; transform one into another (formulae are provided).\nMajor Cognitive Neuroscience\n\napply statistical tests in the context of factorial ANOVA, ANCOVA and Analysis of Repeated measures; interpret the corresponding output; and calculate and interpret effect size estimates relevant for these statistical techniques (e.g., (partial) eta squared)\nMajor Social Sciences\n\napply statistical tests in the context of multiple linear regression models with interaction terms and interpret the corresponding output.\ngauge the reliability of measurements from questionnaires and identify problematic items.\nexplore the dimensionality of questionnaire data."
  },
  {
    "objectID": "index.html#attendance",
    "href": "index.html#attendance",
    "title": "Statistics 1 and 2",
    "section": "Attendance",
    "text": "Attendance\nAttendance is mandatory based on our experience that students who actively participate tend to pass the course, whereas those who do not tend to drop out or fail. All lectures and practicals ‘build’ on each other, so if you have to miss either one, absolutely make sure you have caught up with the materials before the next session."
  },
  {
    "objectID": "index.html#staff",
    "href": "index.html#staff",
    "title": "Statistics 1 and 2",
    "section": "Staff",
    "text": "Staff\nCoordinator:\ndr. Caspar J. van Lissa\nLab sessions\n(Thu) Tra Lê\n\n\n\n\nWhy group assignments?\nContact with fellow students is a key aspect of the university experience. We want to stimulate you to engage with the material and with one another. Therefore, the portfolio assignments are made in groups. There are also aspects of learning in groups that can really improve your knowledge, like peer feedback. To ensure that every group member pulls their weight, the final exam tests each student’s individual comprehension of all material covered in the portfolios.\nGroups comprise 3-5 members and are assigned randomly when the course starts. However, it is allowed to switch with a consenting member of another group, or to join/merge with another small group if your group has become smaller than 3 members. There are three portfolio registration deadlines. At this point, one group member submits the definitive group composition via a Google form.\nWhy use portfolio assessment?\nPortfolio assignments are well-suited for a skills-based course like Statistics 1 & 2. They also take a lot of the pressure off because you can work at your own pace, and keep improving the work until it is good enough. We entrust you with the responsibility of making these portfolio assignments in good faith, without instrumental assistance from outside your group or plagiarism, so I kindly ask you to make good on this trust, and hand in original work to show what you’ve learned.\nStatement on using AI for assignments\nThere is, in principle, nothing wrong with using AI-based tools like ChatGPT, as you will also have access to them in your working life - but be warned: when you use ChatGPT, it is your responsibility to thoroughly check its output for logical consistency and correctness. You may not yet have the level of expertise required to know when ChatGPT generates irrelevant nonsense - but the teacher who grades your work does. Consider this carefully when deciding what makes more sense: doing your work manually, making sure each step is correct - or outsourcing it to AI, and then checking its work before submitting."
  },
  {
    "objectID": "index.html#grading",
    "href": "index.html#grading",
    "title": "Statistics 1 and 2",
    "section": "Grading",
    "text": "Grading\nYour grade is based on three portfolio assignments made in groups, and one individual exam to test comprehension of the material covered in the portfolios.\nPortfolios 40% (3 x 13.3%)\nYou work on the portfolio assignments with your group, both during the lab sessions and outside of class. You hand in your group’s portfolio assignment before the set deadline, at which point it is graded. If your grade is below the passing level of 5.5, your group will have the opportunity to revise the portfolio based on teacher feedback to receive a maximum grade of 6.\nExam 60%\nTo make sure that all students are equally involved in the making of the portfolio assignments, an individual exam assesses comprehension of the material covered therein. It is a digital multiple choice exam. You may bring all course materials to the exam, including the portfolio. The exam consists of a common part and a major-specific part. Note: As per university policy, a guessing correction is applied to your grade."
  },
  {
    "objectID": "index.html#assignments",
    "href": "index.html#assignments",
    "title": "Statistics 1 and 2",
    "section": "Assignments",
    "text": "Assignments\nBelow is a description of the assignments. For each assignment, every element labeled with a lower case letter is graded fail (0 points), pass (1 point), or excellent (1.5 points). Grades are summed for each assignment, and rescaled from 1-10. The final grade is the average across assignments of the rescaled grades. Note the stated word limit for each section. If you can write a good report with fewer words, that’s fine. If you exceed the word limit however, your grade for that section cannot exceed a pass (1 point).\nThe focus of the assignments should me on motivating, reporting, interpreting, and discussing your analyses. You will get a good grade for well-reasoned and discussed analyses.\nSee the Appendices section to access data sources for the assignment.\nAssignment 1\nDescriptive statistics and statistical inference\n\nSelect at least three variables for further analysis, and motivate your selection based on theory, using at least one reference to explain why are you interested in the properties of the selected variables (150 words)\n\nInclude one continuous variable\nInclude one nominal variable\nInclude one ordinal variable\n\n\nDescribe the dataset (200 words + tables/figures)\n\nUse appropriate univariate descriptive statistics for all variables\nPlot data using appropriate plots\nInclude at least one frequency- or crosstable\n\n\nFor a continuous variable:\n\nSelect one or more cutoff values with clinical/societal/statistical relevance\nReport the probability of observing values that fall within/exceed those cutoff values\n\n\nFor a continuous variable:\n\nFormulate a specific null- and alternative hypothesis\nReport a one-sample t-test or Z-test for the specific null-hypothesis\nCalculate the probability of comitting a Type II error\n\n\nDiscuss your analyses (300 words)\n\nExplain your rationale for important modeling decisions\nMotivate your choice for the type of statistics and analyses\nDiscuss assumptions\nDiscuss what you have learned from it and how you might improve it\n\n\nUse APA style throughout your report\nAssignment 2\nGeneral linear model\n\nSelect at least three variables for further analysis, and using at least one reference, explain what research questions you will investigate and what hypotheses you will test (150 words)\n\nInclude one continuous outcome variable\nInclude one continuous predictor\nInclude one nominal or ordinal predictor\n\n\nConstruct a model with only the continuous predictor (200 words)\n\nReport and interpret the different sums of squares\nReport and interpret the explained variance\nConduct a separate correlation analysis. Compare the results with the regression analysis.\n\n\nConstruct a model with only the categorical predictor (200 words)\n\nReport and interpret the model results\nConduct a separate ANOVA or t-test with the same variables, whichever one is suitable. Compare the results with the regression analysis.\n\n\nConstruct a model with both the continuous and categorical predictor (200 words)\n\nReport and interpret the model results\nConduct and report a nested model test\n\n\nDiscuss your analyses (300 words)\n\nExplain your rationale for important modeling decisions\nMotivate your choice for the type of statistics and analyses\nDiscuss assumptions\nDiscuss what you have learned from it and how you might improve it\n\n\nUse APA style throughout your report\nAssignment 3 (BE)\nLogistic regression\n\nSelect at least three variables for further analysis, and using at least one reference, explain what research questions you will investigate and what hypotheses you will test (150 words)\n\nChoose a binary outcome variable\nInclude at least two predictors\n\n\nConstruct a model with only main effects (200 words)\n\nReport and interpret the results\n\n\nConstruct a model with the interaction effect (200 words)\n\nReport and interpret the model results\nConduct and report a nested model test\n\n\nThroughout your report, report confidence intervals. For at least one hypothesis, use interval testing (optionally, alongside p-value based testing).\nDiscuss your analyses (300 words)\n\nExplain your rationale for important modeling decisions\nMotivate your choice for the type of statistics and analyses\nDiscuss assumptions\nDiscuss what you have learned from it and how you might improve it\n\n\nUse APA style throughout your report\nAssignment 3 (SS)\nPsychometrics\nConstruct scale, export scores, use for interaction effects\nMajor SS: GLM VII: Interaction effects (moderation analysis) Major SS: Psychometrics I: Reliability and validity, reliability analysis Major SS: Psychometrics II: Reliability and validity, factor analysis Major SS: Psychometrics III: Reliability and validity, factor analysis\n\nSelect at least constructs for further analysis, and using at least one reference, explain what research questions you will investigate and what hypotheses you will test (150 words)\n\nAt least one of these constructs must be a scale with 3+ items\nInclude at least two predictors\n\n\nConstruct a model with only main effects (200 words)\n\nReport and interpret the results\n\n\nConstruct a model with only main effects (200 words)\n\nReport and interpret the results\n\n\nConstruct a model with the interaction effect (200 words)\n\nReport and interpret the model results\nConduct and report a nested model test\n\n\nThroughout your report, report confidence intervals. For at least one hypothesis, use interval testing (optionally, alongside p-value based testing).\nDiscuss your analyses (300 words)\n\nExplain your rationale for important modeling decisions\nMotivate your choice for the type of statistics and analyses\nDiscuss assumptions\nDiscuss what you have learned from it and how you might improve it\n\n\nUse APA style throughout your report\n\nAssignment 3 (CN)\nMajor CN: GLM IV+: Effect size, post-hoc tests and planned comparison in ANOVA Major CN: GLM IV+: Factorial designs and interaction effects in ANOVA Major CN: GLM IV+: ANCOVA (ANOVA with continuous control variables) Major CN: GLM IV+: Repeated measures ANOVA\nConduct factorial ANOVA Add continuous control variable Report effect sizes and post-hoc tests"
  },
  {
    "objectID": "index.html#credit",
    "href": "index.html#credit",
    "title": "Statistics 1 and 2",
    "section": "Credit",
    "text": "Credit\nThis book was authored by Caspar J. Van Lissa. Its code and layout are derived from Lisa DeBruine’s “booktem”:\n\nDeBruine L, Lakens D (2023). booktem: Methods Book Template. https://github.com/debruine/booktem, https://debruine.github.io/booktem/.\n\nAlso see: https://psyteachr.github.io/"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "1  Introduction to Statistics",
    "section": "",
    "text": "2 Lecture\nA formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material.\nComplete the formative test ideally after you’ve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention\nQuestion 1\nWhat is the primary purpose of statistics?\n\nTo create data visualizationsTo design research studiesTo collect and store dataTo summarize and analyze data\n\nQuestion 2\nWhat is the difference between descriptive statistics and inferential statistics?\n\nDescriptive statistics deals with nominal variables, while inferential statistics deals with ratio variables.Descriptive statistics is used in social sciences, while inferential statistics is used in natural sciences.Descriptive statistics involves analyzing data, while inferential statistics involves collecting data.Descriptive statistics summarize data, while inferential statistics involves making informed guesses about parameters in a larger population.\n\nQuestion 3\nWhat is the purpose of statistical modeling?\n\nTo represent a theory as a testable statistical model.To predict outcomes and explore patterns in dataTo summarize data using graphs and chartsTo make educated guesses about a larger population based on a smaller sampleTo describe the characteristics of a dataset\n\nQuestion 4\nWhat is the empirical cycle in scientific research?\n\nThe process of designing research studies and selecting participantsThe process of formulating a theory, deriving hypotheses, testing these with data, and reflecting on theoryThe process of repeatedly collecting and analyzing dataThe process of summarizing and describing data using statistics\n\nQuestion 5\nWhat is the distinction between population and sample in statistics?\n\nPopulation refers to inferential statistics, while sample refers to descriptive statistics.Population refers to the complete set of potential participants, of which the sample is a subset.Population refers to all participants in a study, while sample refers all participants who provided complete answers.\n\nQuestion 6\nWhat is the variance?\n\nThe measure of dispersion for scores on a continuous variable.The average squared distance of observations to the mean.The average distance of observations to the mean.The distance between the lowest and highest value on a continuous variable.\n\nQuestion 7\nSix students work on a Statistics exam. They obtain the following grades: 8, 9, 5, 6, 7 and 8. The teacher calculates a measure of central tendency, which is equal to 7.5. Which statistic did the teacher calculate?\n\nStandard deviationMedianMeanMode\n\nQuestion 8\nFor which of the three scatterplots below is the correlation coefficient largest?\n\nBCA\n\n\n\n\nShow explanations\n\nQuestion 1\nStatistics is the science concerned with developing and studying methods for analyzing data.\nQuestion 2\nDescriptive statistics are calculated based on sample data; inferential statistics involves using those sample statistics to make best guesses about population parameters and quantify uncertainty about those guesses.\nQuestion 3\nStatistical modeling in particular refers to the process of translating a theoretical model into a statistical model whose coefficients can be estimated using data.\nQuestion 4\nThe empirical cycle is a theoretical cyclical model of knowledge production through scientific research, whereby theory gives rise to hypotheses, which are tested in data, after which the theory is revisited based on the results.\nQuestion 5\nPopulation refers to the complete set of potential participants, of which the sample is a subset.\nQuestion 6\nThe variance is the sum of squared distances of observations to the mean, divided by the number of observations minus one. So calculate:\\(S_{X}^2= \\frac{\\sum_{i=1}^nX_i}{n} = \\frac{(7 + 6 + 8 + 6 + 8)}{5} = 7\\)\nQuestion 7\nFirst rule out improbable answers; the variance is not a measure of central tendency, and all grades are pretty close to each other, so it would be impossible for the variance to be that high. We can see what the mode (most common value) is: it’s 8. So we only choose between mean or median. Mean: calculate \\(\\bar{X}= \\frac{\\sum_{i=1}^nX_i}{n} = \\frac{8 + 9 + 5 + 6 + 7 + 8}{6} = 7.17\\)Median: order the numbers, note that there is an odd number, take the average of the two middle numbers. 5, 6, 7, 8, 8, 9 -&gt; 7.5\nQuestion 8\nCorrelation measures linear association, so eliminate option C. Option B shows a very small correlation - probably 0 or maybe .1. So the correct answer is A, which shows a moderate negative correlation."
  },
  {
    "objectID": "introduction.html#frequency-distributions",
    "href": "introduction.html#frequency-distributions",
    "title": "1  Introduction to Statistics",
    "section": "\n4.1 Frequency Distributions",
    "text": "4.1 Frequency Distributions"
  },
  {
    "objectID": "introduction.html#descriptive-statistics",
    "href": "introduction.html#descriptive-statistics",
    "title": "1  Introduction to Statistics",
    "section": "\n4.2 Descriptive Statistics",
    "text": "4.2 Descriptive Statistics"
  },
  {
    "objectID": "introduction.html#bar-charts-and-histograms",
    "href": "introduction.html#bar-charts-and-histograms",
    "title": "1  Introduction to Statistics",
    "section": "\n4.3 Bar Charts and Histograms",
    "text": "4.3 Bar Charts and Histograms"
  },
  {
    "objectID": "introduction.html#introducing-spss",
    "href": "introduction.html#introducing-spss",
    "title": "1  Introduction to Statistics",
    "section": "\n5.1 Introducing SPSS",
    "text": "5.1 Introducing SPSS\nWelcome everyone to your first lab session for Statistics 1 and 2. Today, we start working with an introduction to SPSS and we calculate a few basic descriptive statistics.\nEach lab session consists of several assignments and includes explanations on how to carry out the analyses in SPSS.\nYou can work at your own pace. If you experience any problems, or if you have any questions, feel free to ask your teacher.\nYou will receive feedback to your answers after you have submitted the practical.\nGood luck!\n\n5.1.1 Step 1\nHi there!\nDuring the lab sessions of this course you will learn how to work with the statistics program IBM SPSS (SPSS for short).\nBackground information is given throughout the exercises. We will occasionally refer to additional reading materials for this course, or other sources (e.g., youtube videos).\nIf you’re working from a student workplace, SPSS is already installed. If you’re working from your own computer, you either have to purchase SPSS, or you can use a free alternative (see Section 3) - but note that, at this point, the instruction text is still focused on SPSS so if there are any differences it will be your responsibility to figure out how to use your software.\nYour first task is to start the SPSS program. You can easily find SPSS via the Windows Start Menu. SPSS may ask about the coding: use Unicode (button to the left). Then there may be another window open that you can close. In the end you should see an empty spread sheet.\nLeave SPSS active during the lab session. Click “Next” when you’re ready.\n\n5.1.2 Step 2\nNow you’ve got SPSS running, we’re ready to go!\nWe will start with a number of introductory exercises using the data file stressLAS.sav Download stressLAS.sav. Please right-click on the link and choose “Save Link As”. Then, save the file on your USB stick or on your personal space (e.g., the m:-drive).\nOpen the file in SPSS. Proceed as follows: via the op menu follow the route: File -&gt; open -&gt; data. SPSS now opens a new window. Search for the file StressLAS.sav and open the file in SPSS.\nNote: If you are using Internet Explorer, you may notice it sometimes saves SPSS files with a different name (ending in .htm instead of .sav). This causes the file to be opened with the web browser instead of SPSS. If this happens to you, please rename the file to its original name, but even better is to use another web browser (e.g, google chrome).\n\n5.1.3 Step 3\nThe file contains data about a study on - you guessed it - stress.\nMore precisely, it contains data on the following variables:\n\n\nstress: Measures whether the participant experiences stress, and where the stress comes from.\n\nsmoke: Measures the smoking behavior of the participant.\n\nrelation: Whether or not the participant is involved in a long-term romantic relationship.\n\noptim: Measures how optimistic the participant is on a scale of 0 to 50.\n\nsatis: Measures of life satisfaction of the participant on a scale of 0 to 50.\n\nnegemo: The amount of negative emotions on a scale of 0 to 50.\n\n5.1.4 Step 4\nAfter opening the data file, you will see the tabs Data View and Variable View at the bottom of your screen.\nMake sure the tab Data View is selected.\nLook at the Data View and describe the data file. What do the rows represent, and what do the columns represent?\n\n5.1.5 Step 5\nNow switch to the Variable View tab.\nThe Variable View lists the variables and their properties. We will not discuss all the columns in detail, but focus on the most important ones, which includes: name, label, values, and measure.\nExplain for each of the columns name, label, values, and measure what aspect of the variable it describes. Also explain the difference between variable name and variable label.\n\n5.1.6 Step 6\nValue Labels\nFor nominal and ordinal variables we have to indicate what the scores represent; that is, we have to assign so called value labels. Value labels are specified under Values.\nIf you click on values for the variable of interest, and then on the blue button with the three dots on the right, SPSS opens a new window that allows you to view, define, or modify the value labels.\nWhat are the value labels for the Stress and what are they for Smoke?\n\n5.1.7 Step 6a\nYou may have noticed that the value labels are missing for the nominal variable Relation.\nAdd the value labels yourself in SPSS such that a score 1 represents “Single” and 2 represents “In a relationship”.\n\n5.1.8 Step 7\nEvery variable has a so-called Measurement Level.\nFirst, summarize the measurement levels in your own words (as if you have to explain it to a fellow student). Then, indicate the measurement level for each of the variables of interest (Stress, Smoking, etc.).\n\n5.1.9 Step 8\nCongratulations, you have completed your first assignment!\nBefore we proceed make sure that you save the data file (via file &gt; save). Because you changed the data, it is important to save the file under a different name. This way, you don’t risk losing the original data.\nIn the next assignment we will generate descriptive statistics for this data."
  },
  {
    "objectID": "introduction.html#plotting-data",
    "href": "introduction.html#plotting-data",
    "title": "1  Introduction to Statistics",
    "section": "\n5.2 Plotting data",
    "text": "5.2 Plotting data\n\n5.2.1 Step 1\nThe first step in any statistical analysis involves inspection of the data at hand by means of descriptive statistics and/or graphical summaries. Descriptive statistics include the mean, standard deviation, minimum and maximum value, amongst others. Examples of graphical summaries are bar charts, histograms, and scatter plots.\nIn this assignment we will look at graphical summaries. In particular, we will look at three: bar charts, histogram, and scatter plots.\nYou may use the same data file as for the previous assignments.\n\n5.2.2 Step 2\nFirst, we will create a bar chart for Stress.\nProceed as follows:\nGraphs &gt; legacy dialogs &gt; bar Select Simple and click on define Select Stress under Category Axis (i.e., the variable at the x-axis) Then Click on OK and consult the graph in the output\n\n5.2.3 Step 3\nYou may have noticed that SPSS by default creates a bar chart with the observed frequency depicted on the y-axis. We will now create a new bar chart and instead ask SPSS to show the percentages on the y-axis.\nProceed as follows:\nGraphs &gt; Legacy Dialogs &gt; Bar Again choose Simple and click on Define Under “Bars represent” choose “% of cases” Click on OK. SPSS will now create a bar chart, where the heights of the bars represent percentages.\n\n5.2.4 Step 4\nNext, we will create a histogram for Negative Emotions.\nProceed as follows:\nGraph &gt; Legacy Dialogs &gt; Histogram Select Negative Emotions under variable, and ask SPSS to Display normal curve (check the box). Click on OK.\nInvestigate the histogram; What is shown on the x-axis and what is shown on the y-axis?\nHow to read the histogram:\n\nx-axis: the scores on the negative emotions (here numbers between 0 and 50). bars represent score ranges; the more respondents with a score in that range, the higher the bar.\ny-axis: the observed number of respondents per score range.\n\n5.2.5 Step 5\nFinally, we will create a scatter plot for Negative Emotions and Life Satisfaction. Scatter plots are very useful to get a first impression of whether variables are associated.\nCreate a scatter plot as follows:\nGraphs &gt; legacy dialogs &gt; scatter/dot Choose Simple Scatter Select Negative Emotions on the x-axis, and Life Satisfaction on the y-axis Click OK\nConsult the output. Look at the scatter plot and see if you understand the graph.\nHow to read a scatter plot:\n\nx-axis represents the scores on Life Satisfaction.\ny-axis represents the scores on Negative Emotions.\nEach dot in the graph is a case, representing how the case scores on both Negative Emotions and Life Satisfaction."
  },
  {
    "objectID": "introduction.html#quiz",
    "href": "introduction.html#quiz",
    "title": "1  Introduction to Statistics",
    "section": "\n5.3 Quiz",
    "text": "5.3 Quiz\n\nDescribe the bar chart; What is shown on the x-axis? \nFrequency of Responses\nPercentages of Responses\nNumeric scores of Stress\nCategories of Stress\nAnd what is shown on the y-axis? \nFrequency of Responses\nNumeric scores of Stress\nCategories of Stress\nPercentages of Responses\nWhat’s the approximate proportion of people experiencing work-related stress? \n66%\n33%\n70%\nWhat can you say about differences in stress levels in the sample? Are most people stressed or not? In other words: How is stress distributed across the three categories? \nEvenly distributed\nMost people report life stress\nMost people report work stress\nMost people report no stress\nDescribe the distribution of Negative Emotions. Are the scores normally distributed (i.e., like a bell-shape)? Really consider why this is / is not the case before checking your answer. \nNot normal\nNormal\nBased on the scatter plot from Step 5, would you expect an association between Negative Emotions and Life Satisfaction? \nSmall negative\nStrong positive\nSmall positive\nNo association"
  },
  {
    "objectID": "introduction.html#descriptive-statistics-1",
    "href": "introduction.html#descriptive-statistics-1",
    "title": "1  Introduction to Statistics",
    "section": "\n5.4 Descriptive Statistics",
    "text": "5.4 Descriptive Statistics\n\n5.4.1 Step 1\nAs explained before, the first step in any statistical analysis involves inspection of the data. In the previous assignment we looked at graphical summaries.\nThis assignment shows you how to explore data using descriptive statistics. Descriptive statistics include values such as the mean, standard deviation, the maximum value and the minimum value.\nUse the same data file as for the previous assignments.\n\n5.4.2 Step 2\nWe will first take a look at the descriptive statistics for Optimism, Life Satisfaction, and Negative Emotions.\nCompute descriptive statistics as follows:\nAnalyze &gt; Descriptive Statistics &gt; Descriptives Select the variables Optimism, Life Satisfaction and Negative Emotions Now click on OK SPSS will open a new window - the output window - including a table with the descriptives for the selected variables.\n\n5.4.3 Step 3\nIn the previous step we computed the average value and standard deviations. However, for nominal and ordinal variables, the average value is meaningless. To explore nominal and ordinal variables we may produce Frequency tables. A frequency table shows the observed percentage for each level of the variable.\nLet’s generate a frequency table for variables Smoke and Relation.\nAnalyze &gt; Descriptive Statistics &gt; Frequencies Select the variables for which you want to have the frequency distribution (i.e., Smoke and Relation) Click OK. SPSS now adds a table with the frequency distributions of the selected variables to the output file.\nNote: SPSS reports percentages and valid percentages. Percentages differ when there are missing values. Because we don’t have missing values here, the numbers are the same. Missing values will be discussed in the next assignment."
  },
  {
    "objectID": "introduction.html#quiz-1",
    "href": "introduction.html#quiz-1",
    "title": "1  Introduction to Statistics",
    "section": "\n5.5 Quiz",
    "text": "5.5 Quiz\n\nHow many participants are in the sample? \nWhat is the mean value of Optimism? \nFor which of the variables is the spread in the scores highest? \nSATIS\nOPTIM\nNEGEMO\nThe minimum and maximum observed scores for Negative Emotions were: [ , ].\nWhat percentage of participants is a non-smoker? \nWhat percentage of participants is in a relationship? \n\n\n5.5.1 Step 4\nOne of the reasons to first inspect descriptive statistics is to have a first check if there are erroneous values in the data file. Erroneous values are values that are out of range, or impossible given the variable envisaged. For example, a person may have mistyped his/her age (e.g., 511 instead of 51).\nNow it’s your task to check for each variable whether there are erroneous values (out of range values) in the file using descriptive statistics and/or graphs.\nUse the descriptive statistics to find any erroneous values.\nOne way to deal with missing values is by removing the entire case. This is not a recommended practice; however, at this point, it is the only method you have learned.\nTo find the cases that have missing values you may sort the data file on a variable with suspect values from high to low (or low to high).\nThis can be done as follows:\nData &gt; Sort Cases Select the variable on which cases should be sorted Select the cases in descending order Click on OK Go the data view and verify that the cases are now ordered.\nRemove the case(s) (i.e., delete the row from the data file) with invalid values.\n\n5.5.2 Step 5\nNow that we’ve “cleaned” the data file it’s time to answer our first research question!\nThe question is: “Are non-smokers in our sample on average more satisfied with their life than smokers?”\nTo answer this question, we need the mean of life satisfaction per smoking group. In order to generate those, we will use the Split File option in SPSS. This is an option in SPSS that allows us to get results for separate groups.\nData &gt; Split File &gt; Compare Groups Select the groups based on the variable Smoke Click OK\nNotice that you don’t see any changes in the data file or anything in the output file yet (!). However, after running the Split file command, SPSS from now will do the analyses per group, as we will see next.\nCompute the mean of Life Satisfaction (via descriptive statistics) and consult the output.\nYou may notice that SPSS provides the means of the non-smoking and smoking group separately. Compare the means for both groups to answer the following questions."
  },
  {
    "objectID": "introduction.html#quiz-2",
    "href": "introduction.html#quiz-2",
    "title": "1  Introduction to Statistics",
    "section": "\n5.6 Quiz",
    "text": "5.6 Quiz\n\nWas there an erroneous value in the data file? If so, type the value of that erroneous value here: \nTo answer this question, only use reasoning. If you delete that value, how do you think the mean of that variable will be affected? \nBecomes smaller\nStays the same\nBecomes larger\nTo answer this question, only use reasoning. If you delete that value, how do you think the standard deviation of that variable will be affected? \nBecomes smaller\nBecomes larger\nStays the same\nTo answer this question, only use reasoning. If you delete that value, how do you think the standard deviation of that variable will be affected? \nBecomes larger\nStays the same\nBecomes smaller\nIn this sample, who are more satisfied with life? \nSmokers\nNon-smokers\nDo you think this also holds for the population of all persons? \nNo\nCan’t tell"
  },
  {
    "objectID": "introduction.html#missing-values",
    "href": "introduction.html#missing-values",
    "title": "1  Introduction to Statistics",
    "section": "\n5.7 Missing Values",
    "text": "5.7 Missing Values\nThis is a short assignment about missing values.\nMissing values are ‘holes in the data matrix’. Missing data is a common issue in empirical research. Respondents may forget to fill in questions or refuse to answer questions (if the latter is the case, we are in trouble). It is important that missing data are adequately handled in data analysis.\nUse the same data file as for the previous assignments.\nIn the previous assignment we activated the split file option. However, we don’t need this split file in the remaining questions, therefore we have to undo the split file option.\nData &gt; split file Choose “Analyze all cases, do not create groups”\nCompute the frequency distribution of stress. Consult the output, and answer the following questions"
  },
  {
    "objectID": "introduction.html#quiz-3",
    "href": "introduction.html#quiz-3",
    "title": "1  Introduction to Statistics",
    "section": "\n5.8 Quiz",
    "text": "5.8 Quiz\n\nWhat is the percentage of respondents who experience No Stress? \nWhich type of stress is most common in the sample? \nWork stress\nLife stress\nNo stress\nFor educational purposes only, we will now create missing values in the data file.\nNavigate to the Data view and delete the value for Stress for the first 10 cases. Notice that you only have to delete the scores for the variable Stress, and not the complete case.\nCompute the frequency distribution for Stress again and compare the new table with the previous one.\nExplain what has changed and why.\n\n\nAnswer\n\nWe can see that the values of Percent and Valid Percent have changed and that a ‘missing’ row has been added to the table. It makes sense that the percentages have changed, as there are now missing values. You may have noticed that the values for Percent and Valid Percent differ. Percentage is obtained by dividing the observed frequency by the total (including respondents with a missing value). Valid Percentage is obtained by dividing the observed frequency by the number of respondents with a valid score (thus, not counting the respondents who had a missing value).\n\nImagine I have a sample of 65 participants, with 3 missing value. Of these participants, 15 reported no stress. What is the percentage of no stress, calculated by hand? \nWhat is the percentage out of valid responses (i.e., valid percent), calculated by hand? \n\nBy deleting the values we created empty cells in the data file. SPSS sees these empty cells as system missing. Some researchers instead use specific values to indicate missing values. For example, we may code missing values by 999 if the respondent refused to answer, and 998 if the respondent accidentally skipped the question. These are examples of user missing values, and we have to specify the values to be coded as missing in the Variable view.\nLet’s try this!\nGo to the Data View, and fill in 999 in the cells that have no value on the variable Stress. Then go to the variable view, look for the column ‘Missing’ and click on Missing for Stress. A new window opens. Specify 999 as a discrete missing value. SPSS now knows that the value 999 stands for “missing observation”. Click OK.\nRe-compute the frequency distribution for Stress.\nExamine how the table changed compared to the previous ones."
  },
  {
    "objectID": "introduction.html#more-descriptive-statistics",
    "href": "introduction.html#more-descriptive-statistics",
    "title": "1  Introduction to Statistics",
    "section": "\n5.9 More Descriptive Statistics",
    "text": "5.9 More Descriptive Statistics\nIn this final assignment, we will continue with descriptive statistics.\nAs mentioned in the lecture, describing the data is an important first step in any research situation.\nFor didactic reasons, we will do some computations by hand, but this is not something you have to do on the exam. However, it is good to experience at least once how the computations work and that the numbers in SPSS are not the result of magic.\nLet’s first look at measures of central tendency:\nConsider the following grades for 10 students: 6, 3, 4, 6, 7, 6, 8, 9, 10, 9.\nCompute (by hand) the mean, median, and mode.\n\n\nRemind me how\n\n\nThe mode is the most common value.\nThe median is the middle value (or mean of two middle values for an equal number)\nThe mean is calculated as the sum of all values, divided by the number of values: \\(\\frac{\\sum_{i=1}^nX_i}{n}\\)\n\n\n\nMeasures of variation\nNext we will look at a measure of variation (i.e., indicating the amount of spread in the observations).\nConsider the grades of 6 students: 2, 7, 6, 7, 8, 9.\nCompute the variance and standard deviation by hand.\n\n\nRemind me how\n\nThe variance is the “average squared distance between observations and the mean”: \\(\\frac{\\sum_{i=1}^n(X_i-\\bar{X})^2}{n-1}\\)\nThe SD is the square root of the variance\nFollow these steps:\n\nCompute the mean, e.g., \\(\\bar{X} = 5\\)\n\nFor each observation, calculate the distance from the mean; e.g., \\(3-5 = -2\\)\n\nSquare these distances, e.g.: \\((-2)^2 = 4\\)\n\nAdd these distances for all observations\nDivide by number of observations minus 1"
  },
  {
    "objectID": "introduction.html#quiz-4",
    "href": "introduction.html#quiz-4",
    "title": "1  Introduction to Statistics",
    "section": "\n5.10 Quiz",
    "text": "5.10 Quiz\n\nWhat is the mean? \nWhat is the median? \nWhat is the mode? \nWhat is the mean? \nWhat is the variance? \nWhat is the standard deviation? \n\nWe now will verify the answer to the question in the previous step using SPSS!\nFirst, we have to enter the data in SPSS. Proceed as follows:\nOpen SPSS (use Unicode, and close the opening windows)\nMake sure that you have the data view on the screen\nType in the grades in SPSS (i.e.: 2, 7, 6, 7, 8, 9):\nGo to variable view and change the name of the variable and provide a meaningful label\nSecond, we can compute the variance and standard deviation in SPSS.\nProceed as follows:\nAnalyze &gt; Descriptive statistics &gt; Descriptives Select the variable you just defined Now click op Options. A new window opens which shows many more descriptive options Enable the variance Click Continue and OK\nConsult the table descriptive statistics in the output window.\nWere your computations correct?"
  },
  {
    "objectID": "introduction.html#correlation",
    "href": "introduction.html#correlation",
    "title": "1  Introduction to Statistics",
    "section": "\n5.11 Correlation",
    "text": "5.11 Correlation\nFor the next few questions we need the data file LAS_SocSc_DataLab2.sav. Download LAS_SocSc_DataLab2.sav. Open the file in SPSS. You will see that the file contains data for six variables, named X1 through X6. We will inspect the associations between pairs of variables (so called bivariate relationships).\nFirst, generate a scatter plot for X1 and X2. Proceed as follows: Graphs &gt; Legacy dialogs &gt; Scatter/dot. Then ask for a Simple scatter. Put X1 on the X-Axis and X2 on the Y-Axis. Describe the association. Take into account whether the relationship follows a straight line (i.e., linearity), is positive or negative (i.e., direction), and whether the relationship seems to be weak, moderate or strong (i.e., strength).\nSecond, generate a scatter plot for X3 and X4. Make sure that X3 is shown on the X-axis and X4 on the Y-axis. Describe the association in terms of linearity, direction and strength.\nThird, generate a scatter plot for X5 and X6. Describe the association in terms of linearity, direction and strength.\n\nIs the relationship between X1-X2 positive? \nTRUE\nFALSE\nIs the relationship between X5-X6 positive? \nTRUE\nFALSE\nIs the relationship between X1-X2 linear? \nTRUE\nFALSE\nIs the relationship between X3-X4 linear? \nTRUE\nFALSE\nGive an indication of the strength of the relationship between X1-X2: \nmoderate\nweak\nstrong\nzero\nGive an indication of the strength of the relationship between X3-X4: \nstrong\nweak\nmoderate\nzero\nGive an indication of the strength of the relationship between X5-X6: \nzero\nstrong\nweak\nmoderate\n\nConsider the relationship between X3 and X4, can you think of an example of two variables that would be associated in this way?\n\n\nShow answer\n\nAny cyclical process;\n\nTime in the day and how far the water reaches up the beach (ebb and flow)\nLocation of the sun in the sky\n\n\n\n5.11.1 Correlation Coefficient\nIn this step we will look at the correlation coefficient as numerical description of linear association.\nNotice that in the previous step we found a non-linear association. The correlation coefficient would not be a valid measure to describe such an association, but nevertheless it is instructive to see why caution should be exercised in drawing conclusions about association from the correlation coefficient alone.\nWe will use SPSS to compute the correlation coefficient.\nAnalyze &gt; Correlate &gt; Bivariate Select X1, X2, … X6 as the variables Click OK\nConsult the table Correlations in the output.\nThere are several values in the table, but we are looking for the Pearson Correlation. The other numbers are the so called significance level, a concept we discuss soon, and the sample size."
  },
  {
    "objectID": "introduction.html#quiz-5",
    "href": "introduction.html#quiz-5",
    "title": "1  Introduction to Statistics",
    "section": "\n5.12 Quiz",
    "text": "5.12 Quiz\n\nWhat is the correlation coefficient for the variables X1 and X2? \nWhat is the correlation coefficient for the variables X2 and X6? \nWhat is the correlation coefficient for the variables X3 and X4? \nCan we interpret this correlation coefficient? \nNo, assumption of normality violated\nNo, assumption of linearity violated\nYes, otherwise SPSS would give an error\nNo, assumption of association violated\nInterpret the correlation between X5 and X6? \nModerate positive\nModerate negative\nWeak positive\nWeak negative"
  },
  {
    "objectID": "tutorial1.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "href": "tutorial1.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "title": "\n2  Lab 1: Introduction\n",
    "section": "\n2.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses",
    "text": "2.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses\nDiscuss with your portfolio group the logic behind hypothesis testing, and how it relates to your personal (and group’s) research interests.\nConsider the following three research descriptions. Formulate H0 and H1 in words. Discuss your answers with your group members.\nResearchers want to know whether it matters for test performance if an exam is completed on a computer or using paper and pencil. Hence, the research question reads: Is there an effect of the type of administration (computer or paper and pencil) on the test performance?\nWhat would be the H0 and HA for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about a mean difference for two independent samples, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu_{computer} = \\mu_{paper}\\) \\(H_A: \\mu_{computer} \\neq \\mu_{paper}\\)\n\nResearchers want to know whether the alcohol consumption among Dutch students differs from the alcohol consumption in the general Dutch population. Using CBS statistics, they know that in the general population the average alcohol consumption is 5.6 glasses a week. The question is whether the average alcohol consumption among students is different from this national average.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about the difference between a mean and a hypothesized value, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu = 5.6\\) \\(H_A: \\mu \\neq 5.6\\)\n\nResearchers want to study whether social isolation is associated with income.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about an association between two variables, without a clearly specified alternative hypothesis. We could thus state:\n\\(H_0: \\rho = 0\\) \\(H_A: \\rho \\neq 0\\)\n\nFormulating the hypothesis is an important very first step in hypotheses testing. Continue with the next assignment, in which we will go through the steps of a hypothesis test."
  },
  {
    "objectID": "tutorial1.html#assignment-2-test-statistics-alpha-and-significance",
    "href": "tutorial1.html#assignment-2-test-statistics-alpha-and-significance",
    "title": "\n2  Lab 1: Introduction\n",
    "section": "\n2.2 Assignment 2: Test Statistics, Alpha and Significance",
    "text": "2.2 Assignment 2: Test Statistics, Alpha and Significance\nIn this assignment we will go through the steps of a hypothesis test.\nWhile going through the steps we will come across the most important concepts related to hypothesis testing.\nFor the next steps, we consider the following situation:\nSuppose we are interested in the personality profile of musicians; that is, we want to know whether, on average, personality characteristics of musicians differ from those of the general population. For now, we’ll only focus on Openness. We pretend that we have collected data among 25 musicians using a validated scale for which previous research has shown that in the general population the scores are normally distributed with mean 50 and SD 15. It is our task to test whether the mean of Openness for musicians differs from the mean in the general population. To keep things simple, we assume that in the population of musicians the SD is the same as in the general population; that is, we assume that LaTeX: \\(\\sigma = 15\\).\nLet openness be the variable of interest. Let \\(\\mu_{musicians}\\) represent the mean openness in the population of musicians. The hypothesis test amounts to testing:\n\\(H0: \\mu_{musicians} = 50\\)\n\\(H1: \\mu_{musicians} \\neq 50\\)\nNow, when we do the hypothesis test, we seek for evidence against the null hypothesis. More specifically, our testing procedure starts with the assumption that H0 represents the truth and as long as we don’t have convincing evidence that our assumption is false we stick to that assumption.\nThe question is, however, when do we have convincing evidence against H0?\nFinding evidence against H0 works as follows:\nIf H0 is true, we expect mean values close to H0. And, if we observe a mean value that is much different from the value under H0, we have convincing evidence against H0. If this happens, we reject H0 as representing the truth and accept the alternative hypothesis, H1.\nHypothesis testing fits Popper’s philosophy of falsification. He introduced this well-known analogy to explain the logic of falsificationism:\n\nSuppose we assume that all Swans are white, \\(H_0: Swans = white\\)\n\nWe would then not expect to observe black ones.\nIf we do observe black swans, our initial hypothesis is called into question.\nThe number of white swans we see (= observations consistent with the hypothesis) does not provide evidence for \\(H_0\\), because there could always be a black swan out there we haven’t observed yet.\n\nSo, the next questions are:\nWhat are the sample values we can expect under H0? When is evidence “convincing” enough? To answer the first question we have to go back to sampling distributions!\nFor the second question, we need a criterion. We have to realize that even if H0 is true, sample values can be far off just by sampling fluctuations (i.e., by chance). The common criterion is: if the observed value is among the 5% most unlikely samples under H0 (i.e. if H0 is true), we reject the null hypothesis.\nLet’s go back to our example about musicians.\nLet X be openness. Under H0 we assume that X is normally distributed with mean 50 and SD equal to 15.\nWhat are the mean and standard deviation of the sampling distribution of the mean under H0 given that the sample size is 25? And what do we call the standard deviation of the sampling distribution?\n(Use what you have learned in the previous lectures. Hint: first make a drawing of the situation, then do the computations).\n\n\nExplanation\n\nSampling distribution:\n\nMean: \\(\\mu = 50\\)\n\nStandard error ( =SD of sampling distribution!): \\(\\sigma_\\bar{X} = \\frac{15}{\\sqrt{25}}= 3\\)\n\n\n\nSuppose we want to indicate sample means that are unlikely if H0 would be true. In particular, we want to know how far the sample mean must be from the hypothesized mean to be among the 5% of all possible samples under H0 that are furthest away from the hypothesized means.\nWhat should the value of the sample mean be to fall within the 5% most deviant samples if the sample size is 25?\n\n\nExplanation\n\nWe are talking about the distribution of the mean; so we need to work with the sampling distribution. We want to know the cut offs that mark the 2.5% highest and 2.5% lowest means. We first have to find the Z-values: they are 1.96 for the highest 2.5%, and (by symmetry) -1.96 marks the 2.5% lowest.\nHence, to be among the 5% of all possible sample means that are most unlikely under H0, the sample mean should be:\nlarger than 50+1.96 x 3 = 55.88 or smaller than 50-1.96 x 3 = 44.12\n\nLet’s do some more exercises on the Z-test.\nSuppose the mean for Openness we found in our sample was 59.\nIf we use a significance level of 5%, would we reject the null hypothesis? \nYes\nNo\nIn the previous step we used cut offs for the sample means to decide about significance. The cut off scores were obtained via the Z-distribution. However, doing all these computations is not necessary (there’s a shortcut!!). In fact, if we know the Z-value for the sample, we can easily find out if the sample is among the 5% of the most unlikely sample means. We only have to compare the value with 1.96 and -1.96 to see whether that is the case.\nIn this course, we will use Z-values for different purposes. In these specific calculations, Z is used as a Test Statistic. A test statistic quantifies evidence against the null hypothesis. In this case, the Z test statistic expresses how far away from the mean under the null hypothesis the observed mean is, in terms of the number of standard errors.\nThe Z test-statistic follows the standard normal distribution. The values 1.96 and -1.96 are called the critical values and they mark the 5% most unlikely sample means under H0. In other words, the critical values mark the reject region for H0.\nSo, if we compute the Z-value for the sample mean, and if that sample value of Z falls in the rejection region, we reject H0 (we found something that is unlikely enough to no longer believe H0 is true). If H0 is rejected we speak of a significant result. See the graph below:\n\nFollowing these steps to test a mean is one example of performing a “Z-test”!\nWe can use the Z-test to test hypotheses about the population mean if we know the population \\(\\sigma\\).\nThe test statistic for the Z-test is:\n\\(z = \\frac{\\bar{X}-\\mu_{H_0}}{\\sigma_\\bar{X}}\\)\nThis statistic is computed using the mean from the sample, the hypothesized mean under H0 and \\(\\sigma\\).\nH0 is rejected at the 5% significance level if z is either larger than 1.96 or smaller than -1.96.\nSo far, we rejected the null hypothesis if the sample is among the 5% most unlikely sample means under H0. This 5% was called the significance level, and is denoted as \\(\\alpha = .05\\). However, we could just as well choose 1% or .5%.\nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .01\\)? \nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .5\\%\\)? \nFor historical reasons, social scientists tend to use \\(\\alpha = 0.05\\) as a default. So in this course, if alpha is not explicitly stated, assume \\(\\alpha = 0.05\\).\nWhen we test hypotheses we reject H0 if the sample we find is unlikely if H0 is true. However, the flip side is that, even though H0 is true, we may find a sample that is much different by chance, and erroneously reject H0. Or, in other words, we could make an error. Rejecting H0 while it is true in reality is called a Type I error!\nConsider the following:\n\nIf H0 is true, and you test at \\(\\alpha = 0.05\\), what is the probability of committing a Type I error?\nWhat is the link between the \\(\\alpha\\)-level and type I error rate?\n\n\n\nExplanation\n\n\nIf H0 is really true (i.e., H0 should not be rejected), then the probability that the sample mean is among the 5% most unlikely is equal to 5%.\nThe alpha level specifies the risk of a Type I error. So if one tests at an alpha level of .05, it means that one accepts a risk of 5% to commit a Type I error.\n\n\nProperties of the Z-test:\nUsed to test hypotheses about the mean in a population, assuming \\(\\sigma\\) known.\nThe test-statistic equals \\(z = \\frac{\\bar{X}-\\mu}{\\sigma_{\\bar{X}}}\\)\nThe test statistic is normally distributed."
  },
  {
    "objectID": "tutorial1.html#assignment-3-z-test",
    "href": "tutorial1.html#assignment-3-z-test",
    "title": "\n2  Lab 1: Introduction\n",
    "section": "\n2.3 Assignment 3: Z-test",
    "text": "2.3 Assignment 3: Z-test\nIn this assignment we will apply the Z-test.\nThis assignment first presents an example, followed by two practice questions.\nA researcher wants to test \\(H_0: \\mu = 50\\) against \\(H_1: \\mu \\neq 50\\)\nData are available from a random sample of 26 respondents. The mean was 53.7. The researcher assumes the SD in the population is 8.5. Perform all steps of the Z-test.\n\n\nExplanation\n\nStep 1: Formulate hypotheses\n\\(H_0: \\mu = 50\\) \\(H_1: \\mu \\neq 50\\)\nStep 2: Compute test statistic\nStandard error: \\(\\frac{8.5}{\\sqrt{26}}=1.667\\)\nTest statistic: \\(z = \\frac{53.7-50}{1.667}=2.212\\)\nStep 3: Decide about significance\n\\(\\alpha = .05\\), so critical values +/- 1.96.\nOur test statistic exceeds this critical value.\nThe sample mean thus falls in the rejection region, and we should conclude that the test is significant so \\(H_0\\) s rejected.\nStep 4: Draw conclusion\nWe have convincing evidence that the population mean differs from 50.\n\nA researcher wants to test whether the population mean is equal to 80. Data are available from a random sample of 60 respondents. The mean was 74. The researchers assume the SD in the population is 40. Perform and report all steps of the Z-test. What is the resulting p-value? \nA researcher wants to test whether the population mean is equal to 500. Data are available from a random sample of 75 respondents. The mean was 546. The researchers assume that the SD in the population is 200. Perform all steps of the Z-test. Use \\(\\alpha = .01\\). Perform and report all steps.\n\n\nShow answer\n\nStep 1: Hypotheses: \\(H_0: \\mu=500\\), \\(H_1: \\mu \\neq 500\\)\nstep 2: Compute Statistic:\n\nstandard error: \\(\\frac{200}{\\sqrt{75}} = 23.094\\)\n\ntest statistic: \\(z = \\frac{546-500}{23.094}=1.992\\)\n\n\nStep 3: Decide about significance.\nZ does not exceed +/- 2.576. This means that Z does not fall in the reject region when tested at the 1% significance level. The test is not significant.\nStep 4: Draw conclusion\n\\(H_0\\) is not rejected."
  },
  {
    "objectID": "tutorial1.html#quiz",
    "href": "tutorial1.html#quiz",
    "title": "\n2  Lab 1: Introduction\n",
    "section": "\n2.4 Quiz",
    "text": "2.4 Quiz\n\n“The null and alternative hypothesis are deduced from the data.” \nTRUE\nFALSE\n“When performing a hypothesis test, we start by assuming \\(H_0\\) is true.” \nTRUE\nFALSE\n“If we reject \\(H_0\\) with \\(\\alpha=0.05\\), then we will also reject it at \\(\\alpha=0.10\\), assuming all other quantities are held constant.” \nTRUE\nFALSE\n\n\nExplanation\n\nThe critical values of \\(\\alpha =0.05\\) are +/- 1.96. Hence, if \\(H_0\\) is rejected it means that z in the sample is larger than 1.96 or smaller than -1.96.”\nThe critical values of \\(\\alpha =0.1\\) are +/- 1.645. This means that for rejecting \\(H_0\\) at this alpha level, that z should be larger than 1.645 or smaller than -1.645. That is implied by the fact that it exceeds +/- 1.96.\n\n“If we reject \\(H_0\\), then \\(H_0\\) is surely wrong.” \nTRUE\nFALSE\n\n\nExplanation\n\nWe should always be aware of the possibility of making a Type I error. The probability of making a Type I error is equal to \\(\\alpha\\).\n\n“Increasing the sample size n (and holding all the rest constant) decreases the probability of a Type I error.” \nTRUE\nFALSE\n\n\nExplanation\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\nThe Type I error is determined by the alpha level.\nIf our sample is among the 5% most unlikely sample means of all possible sample means with the same size under \\(H_0\\), whatever that sample size N may be.\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error."
  },
  {
    "objectID": "tutorial1.html#assignment-4-z-test-and-alpha-levels",
    "href": "tutorial1.html#assignment-4-z-test-and-alpha-levels",
    "title": "\n2  Lab 1: Introduction\n",
    "section": "\n2.5 Assignment 4: Z-test and Alpha-levels",
    "text": "2.5 Assignment 4: Z-test and Alpha-levels\nIn this assignment we will practice some more with the Z-test, meanwhile we will review important concepts of hypothesis testing. In particular, we will look at significance levels.\nTo test hypotheses, we need to specify the “significance level”, usually denoted by \\(\\alpha\\). The significance level is our decision criterion to reject H0.\nThe most common choice is .05. But what does this criterion exactly entail?\nDiscuss with your group what an \\(\\alpha\\) level entails.\n\n\nExplanation\n\nIf we test at an \\(\\alpha\\) of .05 it means that we are willing to reject H0 in favor of H1 if our sample mean belongs to the 5% most extreme scores (2.5% in each tail) under the null hypothesis.\nIf indeed the sample mean is among this 5%, it means that we have observed a sample in a range that is quite unlikely if the null hypothesis would be true and, therefore, justifies rejection of the null hypothesis.\n\nIn the previous assignments you already used the critical values for the Z-test for specific alpha levels.\nFor two-tailed tests, it holds that if the absolute value of Z exceeds the critical value, we may reject \\(H_0\\).\nLet \\(Z_\\text{crit}\\) be the critical value. For the Z-test it holds that:\n\n\n\\(Z_\\text{crit} = 1.65\\), if \\(\\alpha = 0.10\\) (two-tailed)\n\n\\(Z_\\text{crit} = 1.96\\), if \\(\\alpha = 0.05\\) (two-tailed)\n\n\\(Z_\\text{crit} = 2.58\\), if \\(\\alpha = 0.01\\) (two-tailed)"
  },
  {
    "objectID": "tutorial1.html#quiz-1",
    "href": "tutorial1.html#quiz-1",
    "title": "\n2  Lab 1: Introduction\n",
    "section": "\n2.6 Quiz",
    "text": "2.6 Quiz\n\nResearchers want to test whether \\(\\mu=70\\). They assume that \\(\\sigma = 10\\). Researchers found a mean of 72 in a random sample of 40 persons.\nTrue or false:\n\\(H_0\\) can be rejected at one of the three levels discussed above (\\(\\alpha = .10, .05, .01\\). \nTRUE\nFALSE\n“If the two-tailed test is significant at the 5% level, it will also be significant at the 1% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 10% level, it won’t be significant at the 5% level either (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 5% level, it could still be significant at the 5% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is significant at the 1% level, it might not be significant at the 5% level (keeping everything else fixed).” \nTRUE\nFALSE"
  },
  {
    "objectID": "tutorial1.html#assignment-5-p-values",
    "href": "tutorial1.html#assignment-5-p-values",
    "title": "\n2  Lab 1: Introduction\n",
    "section": "\n2.7 Assignment 5: P-values",
    "text": "2.7 Assignment 5: P-values\nWe will now focus on the interpretation of the p-values and how to use the p-values to decide about significance.\nConsider the following situation:\nScores on a test measuring confidence in police are normally distributed in the general population, with \\(\\mu = 500\\) and an \\(\\sigma = 50\\). Researchers want to know if the average confidence level is different for those who have been a victim of crime. They collect data for 60 victims. They find a sample mean of 511. They test \\(H_0: \\mu = 500\\) against \\(H_1: \\mu \\neq 500\\), while assuming that the population variance is \\(\\sigma = 50\\).\nCompute the p-value. Draw a graph for the two-tailed p-value. Write down in your own words and as precise as possible the interpretation of the p-value in the answer box below. Then, discuss your response with your group.\n\n\nExplanation\n\n\nThe p-value represents the proportion of all possible sample means that are further away from our hypothesized mean than the observed sample mean is.\nWe have the sampling distribution with \\(\\mu = 500\\) and \\(\\sigma_\\bar{X} = \\frac{50}{\\sqrt{60}} = 6.455\\).\nFirst, we compute the right-tail area: \\(P(\\bar{X} &gt; 511) = P(Z &gt; 1.70) = 0.0446\\).\nHence, 4.66% of all possible samples is further away from \\(H_0\\) on the right side.\nSecond, we compute the left-tail area. These are the sample means that are more than 11 points from the hypothesized mean to the left \\(P(\\bar{X} &lt; 489) = P(Z &lt; -1.70) = 0.0446\\).\nHence, the two-tailed p-value is 0.0892.\n\n\nIs the test significant at the 5% level? \nTRUE\nFALSE\nIs it significant at the 1% level? \nTRUE\nFALSE\nResearchers test whether \\(\\mu = 90\\). They assume that \\(\\sigma=21\\). The sample mean was 85. Sample size was 50.\nWhat is the two-tailed p-value? \nWhat is the highest level at which the test is significant? \n0.01\n0.005\n0.05\n0.1\nResearchers test whether \\(\\mu = 35\\). They assume \\(\\sigma =16\\). The sample mean was 38. Sample size was 64.\nCompute the two-tailed p-value and indicate which of the following statements is true.\n\nThe test is not significant at 10%, not significant at 5% and not significant at 1%.The test is significant at the 10% and 5% level, but not at the 1% level.The test is significant at the 10% level, but not at 5% or 1% level.The test is significant at the 10%, 5% level, and 1% level.\n\nConsider these true- or false statements:\nIf a two-tailed p-value is .0567 then the test is significant at the 10% level but not at the 5% level. \nTRUE\nFALSE\nIf a two-tailed test is significant at the 5% level but not at the 1% level, then the two-tailed p-value will be less than 0.01. \nTRUE\nFALSE\nA two-tailed p-value of 0.060 indicates that we have 6% chance that the null hypothesis is true. \nTRUE\nFALSE"
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "3  Probability Distributions",
    "section": "",
    "text": "4 Formative Test\nA formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material.\nComplete the formative test ideally after you’ve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention\nQuestion 1\nAn HR advisor is looking for new employees for LEGO. He thinks it is important for them to be creative. Creativity is normally distributed in the population, with a mean of 180 and a standard deviation of 25. A higher score indicates higher creativity. The advisor only wants to select applicants that belong to the 0.015 proportion of most creative people. What cut-off/boundary score for creativity should the HR advisor use?\n\n234.25125.75206.13180.38\n\nQuestion 2\nWhat is probability?\n\nThe proportion of times an outcome was observed in a sample.The proportion of times an outcome would be observed in a random experiment, if it were repeated many times.A measure of association between two categorical variables.The subjective chance of observing a specific outcome in a single random experiment.\n\nQuestion 3\nWhat is a random experiment?\n\nA naturally occurring experiment; for example, comparing participants who grow up in an area where the drinking water is rich in a particular mineral with control participants from another area.Any process with multiple potential outcomes where the probability of each outcome is unknown.An example of the experimental method, where people are assigned to a treatment- or control group.A process with multiple potential outcomes that could be repeated under similar conditions.\n\nQuestion 4\nWhat are discrete random variables?\n\nVariables with a probability distribution.Variables with an infinite number of possible outcomes.Variables with a finite or countable number of possible outcomes.Variables with a normal distribution.\n\nQuestion 5\nWhat information is contained in a frequency distribution?\n\nA measure of association between two categorical variables.A summary of the observed counts of discrete outcomes in a sample.A summary of the observed counts of discrete outcomes in the population.A summary of observed probabilities of discrete outcomes in a sample.\n\nQuestion 6\nWhat is the standard normal distribution?\n\nA contingency table summarizing two categorical variables.A probability distribution where the total probability sums to 1.Any continuous distribution with infinite possible outcomes.A standardized version of the normal distribution with a mean of 0 and a standard deviation of 1.\n\nQuestion 7\nA researcher is interested in the relationship between movie watched and popcorn consumption. She counts the number of people who consume popcorn during a movie, and whether they have watched “Mean Girls”. The results are presented in the table below this quiz. What is P(Popcorn|Mean Girls), rounded to 3 decimal places?\n\n0.060.080.630.04\n\n\n\n\nShow explanations\n\nQuestion 1\nFind the Z-score that matches a right tail probability of .015, and calculate \\((Z*25) + 180\\)\nQuestion 2\n(The frequentist definition of) probability builds upon the idea that you could theoretically repeat the random experiment many times, and calculate the proportion of times a given outcome is observed\nQuestion 3\nA random experiment is a process with multiple potential outcomes that could theoretically be repeated many times under similar conditions.\nQuestion 4\nDiscrete random variables have a finite (=discrete) or countable number of possible outcomes.\nQuestion 5\nFrequency distributions are used to summarize observed outcomes in a sample.\nQuestion 6\nThe standard normal distribution is a standardized version of the normal distribution with a mean of 0 and a standard deviation of 1.\nQuestion 7\nThe question is about the conditional probability of having popcorn given that (|) someone watched mean girls; divide the 151 pp who match this description by the total number of people who watched mean girls."
  },
  {
    "objectID": "probability.html#normal-distribution",
    "href": "probability.html#normal-distribution",
    "title": "3  Probability Distributions",
    "section": "\n5.1 Normal Distribution",
    "text": "5.1 Normal Distribution\nIn this assignment you will practice with the normal distribution.\nThe normal distribution deserves special attention as it is commonly used in statistics for the social sciences. The normal distribution was already derived in the 18 century by DeMoivre, Adrian, and also Gauss*, and since then it played a central role in statistics. More importantly, many attributes in the social sciences are by close approximation normally distributed, as was first discovered by Quetelet. Hence, the normal distribution has great empirical relevance, which comes in handy for our research!\n\nFor that reason, the normal distribution is sometimes referred to as a Gaussian curve.\n\nBefore we start, the concept of a random variable needs to be introduced first. A random variable is a numerical outcome of a chance experiment.\nFor example, a random variable is the number of pips when throwing two dice (here the chance experiment is throwing two dice). Also, the proportion of girls in a random sample of 10 children is a random variable (here the chance experiment is the random selection of 10 children).\nWe also distinguish between continuous and discrete (categorical) random variables.\nA continuous variable can take on infinitely many values. For example, the height of a person is a continuous variable. Take any two persons of different height, and we can always find a third person in between. Discrete variables can take on only particular values. For example, the number of correct of correct answers when a person blindly guesses all the answers is a discrete random variable.\n\nif you want to know, see for example Wikipedia\n\nNormal distributions are distributions for continuous random variables.\nLet’s first have another look at the graphs of the distribution. Under the information button you can find a figure which shows different examples of normal distributions.\nInspection of the graphs of the bell-shape distributions shows that it is a symmetric distribution. We also see that the distributions differ in location (the point on the x-axis where it reaches its maximum) and the spread. In other words, the distribution is characterized by two parameters: the mean and standard deviation. The mean is denoted by the Greek letter \\(\\mu\\) (pronounced as “moo”) and standard deviation is denoted by the Greek letter \\(\\sigma\\) (pronounced as “sigma”).\nCompare the distributions and see how the parameters determine the location (mean) and spread (standard deviation).\n\n5.1.1 Quiz\n\nCorrectly complete the sentence below by filling in the gaps:\nGiven the example “A student guesses the correct answer to 10 multiple choice questions with four answer categories each” the random experiment is \nguessing the correct answer\nthe 4 answer categories\nthe correct answer\nthe number of correct answers and the random variable is \nguessing the correct answer\nthe number of correct answers\nthe 4 answer categories\nthe correct answer.\nAre the following random variables discrete or continuous?\nNumber of heads in 10 throws with a fair coin is continuous. \nTRUE\nFALSE\nTime by train from Tilburg to Eindhoven is continuous. \nTRUE\nFALSE\nThe number of correct answers on a test is continuous. \nTRUE\nFALSE\nThe mean height in a random sample is continuous. \nTRUE\nFALSE\nThe average number of correct answers in a random sample of 100 students is continuous. \nTRUE\nFALSE\nIf the standard deviation (SD) increases, the distribution becomes \nwider\nnarrower\n\n\n5.1.2 “The Empirical Rules”\nAs a first step we may consider some practical rules for working with the normal distribution, the so called “empirical rules”. In particular, if a random variable is normally distributed the following empirical rules apply:\n68% of the values lie within one standard deviation from the mean. 95% of the values lie within two standard deviations from the mean.\nIf we know that a variable is normally distributed, we can also compute probabilities of certain outcomes, so called events. For example, if we know that the scores on a test are normally distributed, we may want to know the probability that a randomly selected person has a score above a certain cut-off (i.e., satisfies a certain selection criterion).\nIn the next few steps, you will practice on how to compute probabilities under the normal distribution. To do so, we have to be able to work with the standard normal distribution (Z-distribution) and accompanying tables.\n\n5.1.3 Quiz\n\nComplete the following sentences:\nIQ scores are normally distributed with mean 100 and an SD of 15. This means that 95% of the persons in the population has an IQ in between \n15\n85\n55\n70 and \n100\n115\n130\n145.\nStudents loan after completing the bachelor is normally distributed with mean 1500 Euros and an SD of 150. This means that 68% of the students ends up with a loan between \n1000\n1485\n1200\n1350 and \n1515\n1650\n1800\n1450.\nWhat is the mean of the standard normal distribution? \nWhat is the SD of the standard normal distribution? \n\n\n5.1.4 Calculating probabilities\nFor the next series of exercises you need to use a Z-table or calculator (e.g., Excel, R online).\nWe have seen that probabilities are related to the area under the curve. This means that for continuous variables we can only find the probability that the outcome falls within a certain interval. For example, the time to complete a task is more than 10 minutes; the IQ is in between 70 and 90.\nNote that there may be different ways to get to the correct answer.\nNumerical Examples\n\n5.1.5 Quiz\n\nConsider a continuous variable X, which is normally distributed with \\(X \\sim(\\mu = 30, \\sigma = 4)\\).\nCompute the following probabilities:\nP(X&gt;36.8): \nP(X&lt;24): \nP(X&lt;35): \nP(28&lt;X&lt;34): \n\n\nExplanation\n\nP(X&gt;36.8):\n\nTransform X into Z: (36.8 − 30)/4 = 1.7\nRead Upper Tail Area for Z = 1.7, which equals 0.0446\nConclusion: P(X&gt;36.8)= 0.0446.\n\nP(X&lt;24):\n\nTransform X into Z: (24 − 30)/4 = -1.5\nBecause the Z-distribution is symmetric, we know that P(Z&lt;−1.5) is equal to P(Z&gt;1.5). The latter probability can be found in the Z-table, which is 0.0668. This is also the probability we are looking for.\nConclusion: P(X&lt;24) = 0.0668.\n\nP(X&lt;35):\n\nThe probability we are looking for equals 1− P(X&gt;35). Thus, we first need P(X&gt;35).\nCompute corresponding Z-value: Z = = 1.25.\nLook for the upper tail area in the Z-table: P(Z&gt;1.25) = .1056.\nThus, the area we are looking for is 1 − .1056 = .8944\nConclusion: P(Z&lt;35) = 0.89444\n\nP(28&lt;X&lt;34):\n\nRemark: there are different ways to come the answer. So the answer below is just one of few possibilities.\nWe need the area under curve between 28 and 34. This area equals 1 minus the tail areas; that is, P(28&lt;X&lt;34) = 1 − P(X&lt;28) − P(X&gt;34)\nLets start with P(X&gt;34). First compute Z= = 1. Via the Z-table we find P(Z&gt;1)= .1587.\nNow determine P(X&lt;28). First compute Z= = −0.5. Via the Z-table we find P(Z&lt;−0.5) = P(Z&gt;0.5) = .3085.\nHence, we have 1 − 0.1587 − 0.3085 = 0.5328\nConclusion: P(28&lt;X&lt;34) = 0.5328.\n\n\nStudents are looking for a new roommate. They read in an article that the time people spend under the shower is in the population normally distributed with mean of 10 and SD of 8 (measured in minutes). Suppose they randomly select a person as their new roommate.\nWhat is the probability that this randomly selected person will spend more than 20 minutes under the shower? \nSuppose “confidence in society” is measured on a continuous scale from 0 (no confidence at all) to 100 (highly confident). Also suppose that confidence is normally distributed in the population with mean 52.6 and SD of 12. One speaks of low confidence if the score falls below 43.\nWhat percentage of the population has low confidence? \nThe scores on a test for aggressive behavior are normally distributed with mean 50 and SD of 10. The test is used to select police officers. In particular, only police officers with scores between 42 and 62 qualify for the job as they are not too aggressive and not too friendly either.\nWhat percentage of the population qualifies as police officer? \n\n\nExplanations\n\nLet X denote time people spend under the shower. We want to know the probability that the person showers for more than 20 minutes; that is, P(X&gt;20) given μ = 10 and σ = 8.\nCompute Z value: (20 −10)/8 =1.25. Hence, we need P(Z&gt;1.25); that is, the area beyond Z = 1.25.\nVia the Z-table (look in the column labelled C) we find: P(Z&gt;1.25) = .1056.\nConclusion: the probability that a random selected person will shower more than 20 minutes is 0.106 (about 11%).\nLet X stands for the confidence level. X is normally distributed with mean = 52.6 and SD = 12. We need P(X&lt;43). That is, we need the area under the curve to the left of 43.\nFirst, transform to Z-scores: X=43 =&gt; Z = (43 −52.6)/12 = −0.8. Thus, we need P(Z&lt;−.8).\nThe left-tail areas are not shown in the Z-table. Therefore, to find the area, we will first look for the area in the other tail; that is, we will look for P(Z&gt;0.8) in the Z-table. The probability equals 0.2119. Because the distribution is symmetric, the left tail area is also 0.2119. This gives us the answer.\nConclusion: about 21.2% in the population has low confidence in society.\nLet X be the test scores. We need to compute P(42&lt;X&lt;62). This area can not be directly found in the Z-table, so we have to take some additional steps. First, because the whole area under the curve is 1, we can say that the area we are looking for is equal to 1 minus the areas in the tail; thus, 1 − P(X&lt;42) − P(X&gt;62). These latter probabilities can be read from the Z-table!\nCompute Z-values: 1 − P(Z&lt;−0.8) − P(Z&gt;1.2). Remember that $Z = .\nDetermine the tail areas: because the distribution is symmetric, we have P(Z&lt;−0.8)=P(Z&gt;0.8). The latter can found in Z-table, which equals .2119. Probability P(Z&gt;1.2) can be directly read from the Z-table, which is .1151.\nHence, 1 − .2119 − .1151 = 1−.327 = .673.\nConclusion: 67.3% of the population qualifies as police officer.\n\nSuppose the time to complete a certain task is normally distributed with mean 8.6 and standard deviation (SD) of 3.5.\nWhat is the probability that a randomly selected person needs more than 11.4 minutes to complete the task? \nAgain, suppose the time to complete a task is normally distributed with mean 8.6 and standard deviation of 3.5.\nComplete the sentence:\n“95% of the participants completes the task within 1.6 and  minutes.”\nScores on a selection test are normally distributed with a mean of 500 and a standard deviation of 50. A person qualifies for the job if they score between 480 and 580.\nWhat is the probability that a randomly selected person will qualify for the job? \nAn IT company is looking for new programmers. To qualify for the job the programmers need to score high on conscientiousness. Therefore, the job applicants need to complete the Conscientiousness scale from the NEO-PI-R (a popular personality inventory for the Big Five personality traits*) as part of the selection procedure. Research has shown that in the population the scores on the scale are normally distributed with a mean of 133.4 and SD of 18.3. To qualify for the job, the conscientiousness of the programmer needs to be among the highest 20% in the population.\nWhat cut-off should the company use to select new personnel? Round to a whole number. \n\nThe Big Five is a popular model for personality; see Wikipedia for more info on the Big Five.\n\n\n\nExplanations\n\nQuestion 1:\n\nTransform X into Z: (11.4 -8.6)/3.5 = 0.8\nRead Upper Tail Area for Z = 0.8, which equals 0.2119\nConclusion: P(X&gt;36.8)= 0.212\n\nQuestion 2:\n95% of the participants completes the task within 1.6 and 15.6 minutes. You can use the empirical rule that 95% of the observations falls within 2SDs from the mean. Thus, 95% of the observations lies within 8.6−2×3.5 and 8.6+2×3.5\nAnd 8.6+2×3.5 = 15.6\nQuestion 3:\nWe need P(480&lt;X&lt;580). This probability equals 1 − P(X&lt;480) − P(X&gt;580).\nP(X&lt;480) = P(Z&lt;−0.4) = P(Z&gt;0.4) = 0.3446 (via Z-table)\nP(X&gt;580) = P(Z&gt;1.6) = P(Z&gt;1.6) = 0.0548 (via Z-table)\nSo the final answer equals: 1−0.3446−0.0548=0.6006 (0.601 when rounded at three decimal places).\nQuestion 4:\nTo get to the correct answer, these are the steps: - First find the Z-value that marks the highest 20%. This value equals 0.84. - Then compute the corresponding cut-off on the X-scale: X = 0.84×18.3 + 133.4 = 148.772 - Rounded to the nearest integer equals 149."
  },
  {
    "objectID": "probability.html#missing-values",
    "href": "probability.html#missing-values",
    "title": "3  Probability Distributions",
    "section": "\n5.2 Missing Values",
    "text": "5.2 Missing Values\nFor this assignment, and also later assignments, we will use a (real) data set on Type D personality and several background characteristics (age, gender, and education level (7 ordered levels)).\nType D personality is defined as the tendency towards negative affectivity (NA) (e.g., worry, irritability, gloom) and social inhibition (SI) (e.g., reticence and a lack of self-assurance). Theory suggests that Type D individuals have poorer health outcomes.\nType D is measured with the DS14 scale. The DS14 consists of 14 items, 7 measuring NA and 7 items measuring SI. Answers are given on a five point scale (scored 0 through 4).\n\nsee also Type D personality on Wikipedia.\n\nOpen the data file TypeDDataSSC.sav Download TypeDDataSSC.savin SPSS. The data file contains the scores on the DS14 items measuring Type D as well as the background variables for 80 respondents.\nGo to the variable view. The content of the items are given under labels and it is indicated whether the item measures NA or SI.\n\n5.2.1 Quiz\n\nIs the first item in the DS14 an indicator of NA or SI? \nSI\nNA\nGo to the data view in SPSS and inspect the data.\nDo you see any missings? \nYes\nNo\nWhat is the valid N of the variable age? \nHow many system missings do we have on gender? \n\n\n5.2.2 Recoding missing values\nRemember that Empty cells are called system missings. There are reasons to use user-specified missing codes instead; for example, this allows you to keep track of reasons for missingness (which enables you to report more comprehensively on your missing data).\nSo, for this exercise we will define a user-missing code for the missing values. Missing code is number that a researcher uses to designate that the value is missing. The code must be chosen such that it cannot be confused with actual scores. For example, for age the missing code can be 999, because 999 is an impossible age.\nNow, we will first define missings for age.\nGo to the data view; look at the values of age and whenever the value is missing fill in 999. (In total three persons had a missing on age; so you have to fill in 999 three times).\nGo to the variable view. We have to define the missing code under missing. Click on the cell and […], and SPSS opens a new window. Define 999 as missing code.\nIn the previous step we filled in the missing codes manually. For a small data set this is okay, but for large data sets (say thousands of persons on many variables) this would be problematic.\nIn the next few steps we will see how we can define the missings more easily.\nTo do so, we will use the function recode in SPSS. We will first apply the recoding to gender.\nBefore going into the recoding, let’s first look at the frequency table for gender.\nYou may already have this output from answering the Quiz.\n\n5.2.3 Recode into Same Variables\nReplacing user missing values with a missing code using the recode option works as follows:\nNavigate to Transform &gt; Recode into the same variables. SPSS opens a new window.\nSelect gender as the variable to be recoded.\nClick on Old and New Values. SPSS opens a new window. In this window we can specify the recoding. In our case we want to recode System Missing into 999. So, choose “system missing” as old Value, and specify 999 as new value, and click on Add below. (See the more info section below for the SPSS specifications.)\nClick on Continue, and click on OK. SPSS now replaced system missing by 999. Go to the data view and verify that SPSS filled in 999 at the empty places.\nGo to the variable view and specify 999 as the user missing code for gender. (In the same way as you did for age).\nCompute the frequency table for gender again.\nVerify that all “system missings” are now reported as “user missings” instead.\nIn the previous step we only recoded the missings for gender, but we could do that for all variables. It is most convenient to use a code that can be used for all variables. In this case we can use 999 as the missing code for all variables, it’s easy because we can apply this recoding to all variables at once. Just follow the same steps as before, but now select all variables to recode.\nRun the recode command for all variables.\nVerify in the data file that SPSS replaced all system missings by 999.\nNow we also have to specify in the variable view that 999 is the missing codes for all variables. We already changed it for age and gender. To do the same thing for other variables is easy; you can just use copy-paste! Click on Missing for gender, click on the right mouse button, choose copy. Go to the next variable, click on the right mouse button, and with paste you can define the missings for other variables.\nTip: If you like shortcuts: you can also click on missing, type Ctrl C, and then use Ctrl V to copy the information about the missings.\nSo, we specified the missing codes, but we also want to know for each respondent how many missings values he or she had. In other words, for each participant we want to count the number of missings. Participants with too many missings may be excluded from further analysis. Counting the number of missings per person can also be easily accomplished in SPSS.\nTransform &gt; Count Values within Cases. SPSS opens a new window. Specify the name of the target variable (e.g., CountMiss); this is the name of a new variable that gives the number of missings. You may also give the variable a label, say: “Number of Missings”.\nSelect all variables.\nClick on Define Values. SPSS opens a new window. Select System or User Missing at the left and click on add. Click on continue than OK.\nSPSS will now create a new variable that shows how many missings there are for each person on the variables selected in the list.\nGo to the data view and verify that SPSS added a new variable (i.e., a new column with values) named CountMiss.\n\n5.2.4 Quiz\n\nCompute the frequency table for the third DS14 item. How many missing values do we have on this item? \nHow many missings does person 8 have, using the variable CountMiss? \nCompute the frequency table for CountMiss.\nWhat is the maximum number of missings for the participants in this dataset? \nHow many participants have this many missings? \nHow many participants have at least one missing value? \n\nMake sure you save the data file including the variable with the number of missings. We will use it in the next assignment. `"
  },
  {
    "objectID": "probability.html#select-cases-and-split-file",
    "href": "probability.html#select-cases-and-split-file",
    "title": "3  Probability Distributions",
    "section": "\n5.3 Select Cases and Split File",
    "text": "5.3 Select Cases and Split File\nIn this assignment we will take a closer look at selecting cases and how to do analyses for subgroups.\n\n5.3.1 Selecting Cases\nIn the previous assignment we have seen that some respondents had one or more missing values. Suppose we want to discard these persons in the analysis, which means that for all the remaining analyses we only want to include participants with no missings. This method of handling missing data is called listwise deletion, and it is generally considered bad practice - but it’s also easy, so we will teach it in this course. More advanced courses cover expert methods of handling missing data.\nProceed as follows:\nData &gt; Select cases. SPSS opens a new window.\nChose “If condition is satisfied” and chose ‘if’. SPSS opens a new window again.\nFirst select the variable CountMiss (Number of Missings) and using the calculator below specify that we want to select cases with no missings. See the more info section what the final screen should look like. Click on Continue.\nMake sure that the output is specified as “Filter out unselected cases”. Click on OK.\nGo to the data view.\nVerify that SPSS crossed out cases with one or more missings.\nVerify that SPSS added a new variable labelled ‘filter_$’. This is filter variable indicating who is included in the analyses (value = 1) or not (value is 0). If you remove the filter variable, SPSS will use all cases again.\n\n5.3.2 Quiz\n\nWhat is the mean for the variable age of the selected group? \nWhat is the valid sample size for that mean? \n\nNow, run the selection procedue again, but remove the incomplete cases from the data file.\nProceed as follows:\nData &gt; Select cases Choose “Delete Unselected Cases” under output. Click OK. Verify that the incomplete cases are removed.\nBecause you have modified the data, it is prudent to save the new file under a different name (e.g., TypeD_selection.sav). Use this file with only the complete cases (i.e., TypeD_selection.sav) for the remaining steps.\n\n5.3.3 Split File\nSometimes we want to do analyses for subgroups, especially when exploring the data for the first time. For example, we may want to have the descriptive statistics for males and females separately. One way to do this is to use the Split File option. With this option you can tell SPSS that you want to have tables for each subgroup separately.\nLet’s see how it works!\nProceed as follows:\nVia menu follow Data &gt; split file. SPSS opens a new window.\nChoose ‘Compare Groups’ and choose gender as the variable for Groups Based on.\nClick OK.\nImportant: Notice no output appears and no changes are made to the data. This makes sense because we haven’t asked SPSS to generate any output nor to make changes in the data. Yet, SPSS now knows that he has to produce tables for males and females separately once we ask to generate output.\nTo undo the split file, proceed as follows.\nData &gt; Split file Choose Analyze all cases, do not create groups. Click OK. SPSS now no longer produces the output per group.\n\n5.3.4 Quiz\n\nHave SPSS compute the mean and SD for age.\nHow many women are there in the sample?  What is the mean age of men in the sample?  What is the mean age of women in the sample? \nOne of the variables is Education Level. It is an ordinal variable with 7 levels, score 1 represents the lowest level of education, and score 7 the highest.\nCompute the mean age per level of education.\nFor which education level was the mean age highest? \nWhat was the value of the mean age for this education level?"
  },
  {
    "objectID": "probability.html#recode-and-compute",
    "href": "probability.html#recode-and-compute",
    "title": "3  Probability Distributions",
    "section": "\n5.4 Recode and Compute",
    "text": "5.4 Recode and Compute\nFor this assignment we will continue with the data on Type D and the selection of complete cases.\nBefore you start, make sure that the Split File option is disabled.\nIn practice, you often have to do some data handling before you can actually start doing analyses. For example by coding missing values, or you may have questionnaire data for which some of the questions are formulated contra-indicative and therefore should be reverse coded. Another reason would be that you may have to compute the total score (e.g., sum or average) for a set of questions.\nIn this assignment we will practice some basic data handling skills.\n\n5.4.1 Reverse Scoring Contra Indicative Items\nIf you read the item labels, you will see that the first two SI items (items DS14_1 and DS14_3 in the scale) are contra indicative. This means that for these items higher scores reflect low SI, while for other items higher scores reflect high SI. Therefore, the responses to these items should be recoded first to make sure that all items are scored in the same direction. To do so, we will create new variables that reflect the recoded items. Proceed as follows:\nTransform &gt; Recode into different Variables\nChoose DS14_1 as the Numerical Variable to be recoded\nSpecify a name for the output variable (say DS14_1R)\nGive a label, say: “SI item 1 (recoded)”\nClick on change\nDo not close the window yet, but continue to the next step…\nTo recode, we have to specify the Old Values and New values. Reverse scoring of the DS14 items means that\nold value 0 -&gt; new value 4\nold value 1 -&gt; new value 3\nold value 2 -&gt; new value 2 (*)\nold value 3 -&gt; new value 1\nold value 4 -&gt; new value 0\n(*) You may think this line is superfluous but for the recoding in SPSS you need to specify for every possible value a recoded new value, even if the values remains the same.\nSpecify the old and new values. Each time you specified old and new values click on ADD such that the recoding scheme appears in the little dialog."
  },
  {
    "objectID": "probability.html#using-syntax",
    "href": "probability.html#using-syntax",
    "title": "3  Probability Distributions",
    "section": "\n5.5 Using Syntax",
    "text": "5.5 Using Syntax\nTo ensure that others can see exactly how you got from raw data to the final dataset used for analysis, it is essential to keep a complete record of any changes made to the data. This is also why we previously argued that you should not overwrite a datafile after altering it.\nUp until now, we ran the analyses by “click-and-point” via the menu. This is a good starting point to explore the software SPSS, but it is not good practice for professional use because there’s no record of what you did to the data in order to get your result.\nNOTE: For all your portfolio assignments, providing syntax is mandatory so I can grade what you DID, not just what you reported!\nTo keep a record of changes made to your data, you can prepare a script that contains all instructions for the analysis instead. By evaluating this script on the data, you should consistently get the same results.\n\n5.5.1 Why syntax?\nUsing syntax is important for several reasons:\n\nFirst, efficiency: it makes life easier. Once you have the syntax, you can easily redo the whole analysis without going through all the points-and-clicks again.\nSecond, communication: When you work together on research projects, it is important that you exactly understand the analyses that were done, even if you didn’t do the analyses yourself. By using syntax, all team members can see what has been done and how.\nThird, documentation & data management: As a researcher you are responsible for data storage and management (!). This not only includes storage of data, but also documentation of the all the steps and analyses you did to come to your results (e.g., handling missing values, detection of outlying values). Ideally, you should provide the materials such that other researchers can easily replicate your analyses starting from the raw data file. Working with SPSS syntax is a great way to do so.\nFourth, necessity: some statistical procedures are only available via SPSS syntax (e.g., simple effects analysis in MANOVA).\n\n\n5.5.2 Help!\nYou don’t need to memorize the commands by heart. SPSS offers help functions. If you highlight the command (e.g., statistics) and click on the button with the paper and the question mark in the top menu. SPSS opens a help file.\nUse the help function to modify the syntax such that SPSS produces a table that also reports the range (e.g., the difference between the largest and smallest value).\n\n5.5.3 How to use syntax\nThere are two ways to use syntax. The first is to create an empty syntax script via File -&gt; New -&gt; Syntax, and then start adding the code from scratch. You can either write the code as text, or create it via SPSS’ various dialog windows. For this course, we recommend using the dialogs:\n\nIn any dialog window, click “Paste” instead of “OK”.\nA new window opens (or existing window comes into focus) with a script file (or “syntax” file). The instructions for the requested analysis are added at the bottom of this file.\nSelect all instructions you wish to execute, and press the green “Play” button.\nYou can re-organize this script file, adding, or removing operations or changing their order. Keep it nice and organized!\n\n\n\nSyntax for recoding\n\nSelect the highlighted lines and press the green “Play” button. Verify in the data view that SPSS added a new variable (i.e., new column) with the recoded values for Item 1.\nSyntax is also useful because it may be more straightforward than the graphical interface. For example, the recode syntax above took a lot of pointing and clicking to get:\nRECODE DS14_1 (0=4) (1=3) (3=1) (4=0) INTO DS14_1R.\nEXECUTE.\nFor recoding more variables, we can copy-paste these instructions and change the variable names.\nFor example, to recode DS14_3 in the same way as you did the recoding for DS14_1 we would write:\nRECODE DS14_1 (0=4) (1=3) (3=1) (4=0) INTO DS14_1R.\nRECODE DS14_3 (0=4) (1=3) (3=1) (4=0) INTO DS14_3R.\nEXECUTE.\nAlternatively, we could simply say:\nCOMPUTE DS14_1R = 4-DS14_1.\nCOMPUTE DS14_3R = 4-DS14_3.\nEXECUTE.\nVerify that this calculation also works.\n\n5.5.4 Commenting\nWhen working with syntax, it is highly recommended to add comments as reminders to your future self of the purpose of each step in the script. These comments should clarify the syntax and give general information (e.g., when was the syntax last modified, who did the modifications, etc.).\nComments are text lines that start with an * and ends with a dot. Comments are printed in grey.\nREMARK: the dot at the end of your text line is really important. If you do not add it, your syntax will run work properly!\nAdd comments including the following information:\n\nWhen was the syntax made?\nWho made syntax?\nWhat does the syntax do?\n\nFor example (CJ is short for Caspar J. Van Lissa):\n* CJ: This script also recodes Likert scales with integer values.\nCOMPUTE DS14_1R = 4-DS14_1.\nCOMPUTE DS14_3R = 4-DS14_3.\nEXECUTE.\nAfter including the comments, run the complete syntax including the comment line (by selecting and running it, or via top menu Run &gt; All).\nIf the syntax runs correctly, the comments were correctly included.\n\n5.5.5 Compute Variable\nFor the analyses we are not interested in the single item scores but in the summed scores. Because the DS14 contains two subscales (consult the item labels to see to which subscale the item belongs), we want to compute the summed scores for the NA and SI items separately.\nLet’s first do this for NA. Proceed as follows:\nTransform &gt; Compute variable. SPSS opens a new window.\nChoose a name for the target variable, say: NAtotal.\nUnder numerical expression you have to say what you want to compute. In this case the sum of the NA items, which is DS14_2 + DS14_4 + … etc. So, select the first item to be summed from the list at the left, type +, select the next item you want to add, and so on. Make sure that you only add up the NA items (in the variable view you can see which items measure NA and which measure SI).\nClick Paste, and run the code.\nAlternatively, copy-paste this syntax, complete it and run it:\nCOMPUTE NAtotal = DS14_2 + DS14_4 + .\nCOMPUTE SItotal = .\nEXECUTE.\n\n5.5.6 Quiz\n\nCompute the frequency table for the recoded DS14_3 item.\nWhat percentage of the respondents had the highest score on this item? \nWhat is the mean of NAtotal? \nCompute the mean of NAtotal for men and women separately. For which group is the mean highest? (Hint: Use the skills you’ve learned in the previous assignments). \nWomen\nMen\nCompute the total scores for SI. Make sure you use the reverse scored items for items 1 and 3 to compute the total score (this implies you have to leave the original item 1 and 3 out).\nWhat is the mean of SI in the total sample? \nWhat is the mean for the subsample of men?"
  },
  {
    "objectID": "samplingdistribution.html",
    "href": "samplingdistribution.html",
    "title": "4  The Sampling Distribution",
    "section": "",
    "text": "5 Tutorial"
  },
  {
    "objectID": "samplingdistribution.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "href": "samplingdistribution.html#assignment-1-hypothesis-testing---formulating-hypotheses",
    "title": "4  The Sampling Distribution",
    "section": "\n5.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses",
    "text": "5.1 Assignment 1: Hypothesis Testing - Formulating Hypotheses\nDiscuss with your portfolio group the logic behind hypothesis testing, and how it relates to your personal (and group’s) research interests.\nConsider the following three research descriptions. Formulate H0 and H1 in words. Discuss your answers with your group members.\nResearchers want to know whether it matters for test performance if an exam is completed on a computer or using paper and pencil. Hence, the research question reads: Is there an effect of the type of administration (computer or paper and pencil) on the test performance?\nWhat would be the H0 and HA for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about a mean difference for two independent samples, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu_{computer} = \\mu_{paper}\\) \\(H_A: \\mu_{computer} \\neq \\mu_{paper}\\)\n\nResearchers want to know whether the alcohol consumption among Dutch students differs from the alcohol consumption in the general Dutch population. Using CBS statistics, they know that in the general population the average alcohol consumption is 5.6 glasses a week. The question is whether the average alcohol consumption among students is different from this national average.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about the difference between a mean and a hypothesized value, without a clearly specified alternative hypothesis. Thus, we could state:\n\\(H_0: \\mu = 5.6\\) \\(H_A: \\mu \\neq 5.6\\)\n\nResearchers want to study whether social isolation is associated with income.\nWhat would be the H0 and H1 for this study?\n\n\nShow answer\n\nThis appears to be an undirected hypothesis about an association between two variables, without a clearly specified alternative hypothesis. We could thus state:\n\\(H_0: \\rho = 0\\) \\(H_A: \\rho \\neq 0\\)\n\nFormulating the hypothesis is an important very first step in hypotheses testing. Continue with the next assignment, in which we will go through the steps of a hypothesis test."
  },
  {
    "objectID": "samplingdistribution.html#assignment-2-test-statistics-alpha-and-significance",
    "href": "samplingdistribution.html#assignment-2-test-statistics-alpha-and-significance",
    "title": "4  The Sampling Distribution",
    "section": "\n5.2 Assignment 2: Test Statistics, Alpha and Significance",
    "text": "5.2 Assignment 2: Test Statistics, Alpha and Significance\nIn this assignment we will go through the steps of a hypothesis test.\nWhile going through the steps we will come across the most important concepts related to hypothesis testing.\nFor the next steps, we consider the following situation:\nSuppose we are interested in the personality profile of musicians; that is, we want to know whether, on average, personality characteristics of musicians differ from those of the general population. For now, we’ll only focus on Openness. We pretend that we have collected data among 25 musicians using a validated scale for which previous research has shown that in the general population the scores are normally distributed with mean 50 and SD 15. It is our task to test whether the mean of Openness for musicians differs from the mean in the general population. To keep things simple, we assume that in the population of musicians the SD is the same as in the general population; that is, we assume that LaTeX: \\(\\sigma = 15\\).\nLet openness be the variable of interest. Let \\(\\mu_{musicians}\\) represent the mean openness in the population of musicians. The hypothesis test amounts to testing:\n\\(H0: \\mu_{musicians} = 50\\)\n\\(H1: \\mu_{musicians} \\neq 50\\)\nNow, when we do the hypothesis test, we seek for evidence against the null hypothesis. More specifically, our testing procedure starts with the assumption that H0 represents the truth and as long as we don’t have convincing evidence that our assumption is false we stick to that assumption.\nThe question is, however, when do we have convincing evidence against H0?\nFinding evidence against H0 works as follows:\nIf H0 is true, we expect mean values close to H0. And, if we observe a mean value that is much different from the value under H0, we have convincing evidence against H0. If this happens, we reject H0 as representing the truth and accept the alternative hypothesis, H1.\nHypothesis testing fits Popper’s philosophy of falsification. He introduced this well-known analogy to explain the logic of falsificationism:\n\nSuppose we assume that all Swans are white, \\(H_0: Swans = white\\)\n\nWe would then not expect to observe black ones.\nIf we do observe black swans, our initial hypothesis is called into question.\nThe number of white swans we see (= observations consistent with the hypothesis) does not provide evidence for \\(H_0\\), because there could always be a black swan out there we haven’t observed yet.\n\nSo, the next questions are:\nWhat are the sample values we can expect under H0? When is evidence “convincing” enough? To answer the first question we have to go back to sampling distributions!\nFor the second question, we need a criterion. We have to realize that even if H0 is true, sample values can be far off just by sampling fluctuations (i.e., by chance). The common criterion is: if the observed value is among the 5% most unlikely samples under H0 (i.e. if H0 is true), we reject the null hypothesis.\nLet’s go back to our example about musicians.\nLet X be openness. Under H0 we assume that X is normally distributed with mean 50 and SD equal to 15.\nWhat are the mean and standard deviation of the sampling distribution of the mean under H0 given that the sample size is 25? And what do we call the standard deviation of the sampling distribution?\n(Use what you have learned in the previous lectures. Hint: first make a drawing of the situation, then do the computations).\n\n\nExplanation\n\nSampling distribution:\n\nMean: \\(\\mu = 50\\)\n\nStandard error ( =SD of sampling distribution!): \\(\\sigma_\\bar{X} = \\frac{15}{\\sqrt{25}}= 3\\)\n\n\n\nSuppose we want to indicate sample means that are unlikely if H0 would be true. In particular, we want to know how far the sample mean must be from the hypothesized mean to be among the 5% of all possible samples under H0 that are furthest away from the hypothesized means.\nWhat should the value of the sample mean be to fall within the 5% most deviant samples if the sample size is 25?\n\n\nExplanation\n\nWe are talking about the distribution of the mean; so we need to work with the sampling distribution. We want to know the cut offs that mark the 2.5% highest and 2.5% lowest means. We first have to find the Z-values: they are 1.96 for the highest 2.5%, and (by symmetry) -1.96 marks the 2.5% lowest.\nHence, to be among the 5% of all possible sample means that are most unlikely under H0, the sample mean should be:\nlarger than 50+1.96 x 3 = 55.88 or smaller than 50-1.96 x 3 = 44.12\n\nLet’s do some more exercises on the Z-test.\nSuppose the mean for Openness we found in our sample was 59.\nIf we use a significance level of 5%, would we reject the null hypothesis? \nYes\nNo\nIn the previous step we used cut offs for the sample means to decide about significance. The cut off scores were obtained via the Z-distribution. However, doing all these computations is not necessary (there’s a shortcut!!). In fact, if we know the Z-value for the sample, we can easily find out if the sample is among the 5% of the most unlikely sample means. We only have to compare the value with 1.96 and -1.96 to see whether that is the case.\nIn this course, we will use Z-values for different purposes. In these specific calculations, Z is used as a Test Statistic. A test statistic quantifies evidence against the null hypothesis. In this case, the Z test statistic expresses how far away from the mean under the null hypothesis the observed mean is, in terms of the number of standard errors.\nThe Z test-statistic follows the standard normal distribution. The values 1.96 and -1.96 are called the critical values and they mark the 5% most unlikely sample means under H0. In other words, the critical values mark the reject region for H0.\nSo, if we compute the Z-value for the sample mean, and if that sample value of Z falls in the rejection region, we reject H0 (we found something that is unlikely enough to no longer believe H0 is true). If H0 is rejected we speak of a significant result. See the graph below:\n\nFollowing these steps to test a mean is one example of performing a “Z-test”!\nWe can use the Z-test to test hypotheses about the population mean if we know the population \\(\\sigma\\).\nThe test statistic for the Z-test is:\n\\(z = \\frac{\\bar{X}-\\mu_{H_0}}{\\sigma_\\bar{X}}\\)\nThis statistic is computed using the mean from the sample, the hypothesized mean under H0 and \\(\\sigma\\).\nH0 is rejected at the 5% significance level if z is either larger than 1.96 or smaller than -1.96.\nSo far, we rejected the null hypothesis if the sample is among the 5% most unlikely sample means under H0. This 5% was called the significance level, and is denoted as \\(\\alpha = .05\\). However, we could just as well choose 1% or .5%.\nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .01\\)? \nWhat would be the critical values for the Z-test if one tests at \\(\\alpha = .5\\%\\)? \nFor historical reasons, social scientists tend to use \\(\\alpha = 0.05\\) as a default. So in this course, if alpha is not explicitly stated, assume \\(\\alpha = 0.05\\).\nWhen we test hypotheses we reject H0 if the sample we find is unlikely if H0 is true. However, the flip side is that, even though H0 is true, we may find a sample that is much different by chance, and erroneously reject H0. Or, in other words, we could make an error. Rejecting H0 while it is true in reality is called a Type I error!\nConsider the following:\n\nIf H0 is true, and you test at \\(\\alpha = 0.05\\), what is the probability of committing a Type I error?\nWhat is the link between the \\(\\alpha\\)-level and type I error rate?\n\n\n\nExplanation\n\n\nIf H0 is really true (i.e., H0 should not be rejected), then the probability that the sample mean is among the 5% most unlikely is equal to 5%.\nThe alpha level specifies the risk of a Type I error. So if one tests at an alpha level of .05, it means that one accepts a risk of 5% to commit a Type I error.\n\n\nProperties of the Z-test:\nUsed to test hypotheses about the mean in a population, assuming \\(\\sigma\\) known.\nThe test-statistic equals \\(z = \\frac{\\bar{X}-\\mu}{\\sigma_{\\bar{X}}}\\)\nThe test statistic is normally distributed."
  },
  {
    "objectID": "samplingdistribution.html#assignment-3-z-test",
    "href": "samplingdistribution.html#assignment-3-z-test",
    "title": "4  The Sampling Distribution",
    "section": "\n5.3 Assignment 3: Z-test",
    "text": "5.3 Assignment 3: Z-test\nIn this assignment we will apply the Z-test.\nThis assignment first presents an example, followed by two practice questions.\nA researcher wants to test \\(H_0: \\mu = 50\\) against \\(H_1: \\mu \\neq 50\\)\nData are available from a random sample of 26 respondents. The mean was 53.7. The researcher assumes the SD in the population is 8.5. Perform all steps of the Z-test.\n\n\nExplanation\n\nStep 1: Formulate hypotheses\n\\(H_0: \\mu = 50\\) \\(H_1: \\mu \\neq 50\\)\nStep 2: Compute test statistic\nStandard error: \\(\\frac{8.5}{\\sqrt{26}}=1.667\\)\nTest statistic: \\(z = \\frac{53.7-50}{1.667}=2.212\\)\nStep 3: Decide about significance\n\\(\\alpha = .05\\), so critical values +/- 1.96.\nOur test statistic exceeds this critical value.\nThe sample mean thus falls in the rejection region, and we should conclude that the test is significant so \\(H_0\\) s rejected.\nStep 4: Draw conclusion\nWe have convincing evidence that the population mean differs from 50.\n\nA researcher wants to test whether the population mean is equal to 80. Data are available from a random sample of 60 respondents. The mean was 74. The researchers assume the SD in the population is 40. Perform and report all steps of the Z-test. What is the resulting p-value? \nA researcher wants to test whether the population mean is equal to 500. Data are available from a random sample of 75 respondents. The mean was 546. The researchers assume that the SD in the population is 200. Perform all steps of the Z-test. Use \\(\\alpha = .01\\). Perform and report all steps.\n\n\nShow answer\n\nStep 1: Hypotheses: \\(H_0: \\mu=500\\), \\(H_1: \\mu \\neq 500\\)\nstep 2: Compute Statistic:\n\nstandard error: \\(\\frac{200}{\\sqrt{75}} = 23.094\\)\n\ntest statistic: \\(z = \\frac{546-500}{23.094}=1.992\\)\n\n\nStep 3: Decide about significance.\nZ does not exceed +/- 2.576. This means that Z does not fall in the reject region when tested at the 1% significance level. The test is not significant.\nStep 4: Draw conclusion\n\\(H_0\\) is not rejected."
  },
  {
    "objectID": "samplingdistribution.html#quiz",
    "href": "samplingdistribution.html#quiz",
    "title": "4  The Sampling Distribution",
    "section": "\n5.4 Quiz",
    "text": "5.4 Quiz\n\n“The null and alternative hypothesis are deduced from the data.” \nTRUE\nFALSE\n“When performing a hypothesis test, we start by assuming \\(H_0\\) is true.” \nTRUE\nFALSE\n“If we reject \\(H_0\\) with \\(\\alpha=0.05\\), then we will also reject it at \\(\\alpha=0.10\\), assuming all other quantities are held constant.” \nTRUE\nFALSE\n\n\nExplanation\n\nThe critical values of \\(\\alpha =0.05\\) are +/- 1.96. Hence, if \\(H_0\\) is rejected it means that z in the sample is larger than 1.96 or smaller than -1.96.”\nThe critical values of \\(\\alpha =0.1\\) are +/- 1.645. This means that for rejecting \\(H_0\\) at this alpha level, that z should be larger than 1.645 or smaller than -1.645. That is implied by the fact that it exceeds +/- 1.96.\n\n“If we reject \\(H_0\\), then \\(H_0\\) is surely wrong.” \nTRUE\nFALSE\n\n\nExplanation\n\nWe should always be aware of the possibility of making a Type I error. The probability of making a Type I error is equal to \\(\\alpha\\).\n\n“Increasing the sample size n (and holding all the rest constant) decreases the probability of a Type I error.” \nTRUE\nFALSE\n\n\nExplanation\n\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error.\nThe Type I error is determined by the alpha level.\nIf our sample is among the 5% most unlikely sample means of all possible sample means with the same size under \\(H_0\\), whatever that sample size N may be.\nIncreasing the sample size n (and holding all the rest constant) does not decrease the probability of a Type I error."
  },
  {
    "objectID": "samplingdistribution.html#assignment-4-z-test-and-alpha-levels",
    "href": "samplingdistribution.html#assignment-4-z-test-and-alpha-levels",
    "title": "4  The Sampling Distribution",
    "section": "\n5.5 Assignment 4: Z-test and Alpha-levels",
    "text": "5.5 Assignment 4: Z-test and Alpha-levels\nIn this assignment we will practice some more with the Z-test, meanwhile we will review important concepts of hypothesis testing. In particular, we will look at significance levels.\nTo test hypotheses, we need to specify the “significance level”, usually denoted by \\(\\alpha\\). The significance level is our decision criterion to reject H0.\nThe most common choice is .05. But what does this criterion exactly entail?\nDiscuss with your group what an \\(\\alpha\\) level entails.\n\n\nExplanation\n\nIf we test at an \\(\\alpha\\) of .05 it means that we are willing to reject H0 in favor of H1 if our sample mean belongs to the 5% most extreme scores (2.5% in each tail) under the null hypothesis.\nIf indeed the sample mean is among this 5%, it means that we have observed a sample in a range that is quite unlikely if the null hypothesis would be true and, therefore, justifies rejection of the null hypothesis.\n\nIn the previous assignments you already used the critical values for the Z-test for specific alpha levels.\nFor two-tailed tests, it holds that if the absolute value of Z exceeds the critical value, we may reject \\(H_0\\).\nLet \\(Z_\\text{crit}\\) be the critical value. For the Z-test it holds that:\n\n\n\\(Z_\\text{crit} = 1.65\\), if \\(\\alpha = 0.10\\) (two-tailed)\n\n\\(Z_\\text{crit} = 1.96\\), if \\(\\alpha = 0.05\\) (two-tailed)\n\n\\(Z_\\text{crit} = 2.58\\), if \\(\\alpha = 0.01\\) (two-tailed)"
  },
  {
    "objectID": "samplingdistribution.html#quiz-1",
    "href": "samplingdistribution.html#quiz-1",
    "title": "4  The Sampling Distribution",
    "section": "\n5.6 Quiz",
    "text": "5.6 Quiz\n\nResearchers want to test whether \\(\\mu=70\\). They assume that \\(\\sigma = 10\\). Researchers found a mean of 72 in a random sample of 40 persons.\nTrue or false:\n\\(H_0\\) can be rejected at one of the three levels discussed above (\\(\\alpha = .10, .05, .01\\). \nTRUE\nFALSE\n“If the two-tailed test is significant at the 5% level, it will also be significant at the 1% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 10% level, it won’t be significant at the 5% level either (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is not significant at the 5% level, it could still be significant at the 5% level (keeping everything else fixed).” \nTRUE\nFALSE\n“If the two-tailed test is significant at the 1% level, it might not be significant at the 5% level (keeping everything else fixed).” \nTRUE\nFALSE"
  },
  {
    "objectID": "samplingdistribution.html#assignment-5-p-values",
    "href": "samplingdistribution.html#assignment-5-p-values",
    "title": "4  The Sampling Distribution",
    "section": "\n5.7 Assignment 5: P-values",
    "text": "5.7 Assignment 5: P-values\nWe will now focus on the interpretation of the p-values and how to use the p-values to decide about significance.\nConsider the following situation:\nScores on a test measuring confidence in police are normally distributed in the general population, with \\(\\mu = 500\\) and an \\(\\sigma = 50\\). Researchers want to know if the average confidence level is different for those who have been a victim of crime. They collect data for 60 victims. They find a sample mean of 511. They test \\(H_0: \\mu = 500\\) against \\(H_1: \\mu \\neq 500\\), while assuming that the population variance is \\(\\sigma = 50\\).\nCompute the p-value. Draw a graph for the two-tailed p-value. Write down in your own words and as precise as possible the interpretation of the p-value in the answer box below. Then, discuss your response with your group.\n\n\nExplanation\n\n\nThe p-value represents the proportion of all possible sample means that are further away from our hypothesized mean than the observed sample mean is.\nWe have the sampling distribution with \\(\\mu = 500\\) and \\(\\sigma_\\bar{X} = \\frac{50}{\\sqrt{60}} = 6.455\\).\nFirst, we compute the right-tail area: \\(P(\\bar{X} &gt; 511) = P(Z &gt; 1.70) = 0.0446\\).\nHence, 4.66% of all possible samples is further away from \\(H_0\\) on the right side.\nSecond, we compute the left-tail area. These are the sample means that are more than 11 points from the hypothesized mean to the left \\(P(\\bar{X} &lt; 489) = P(Z &lt; -1.70) = 0.0446\\).\nHence, the two-tailed p-value is 0.0892.\n\n\nIs the test significant at the 5% level? \nTRUE\nFALSE\nIs it significant at the 1% level? \nTRUE\nFALSE\nResearchers test whether \\(\\mu = 90\\). They assume that \\(\\sigma=21\\). The sample mean was 85. Sample size was 50.\nWhat is the two-tailed p-value? \nWhat is the highest level at which the test is significant? \n0.1\n0.01\n0.05\n0.005\nResearchers test whether \\(\\mu = 35\\). They assume \\(\\sigma =16\\). The sample mean was 38. Sample size was 64.\nCompute the two-tailed p-value and indicate which of the following statements is true.\n\nThe test is significant at the 10%, 5% level, and 1% level.The test is not significant at 10%, not significant at 5% and not significant at 1%.The test is significant at the 10% level, but not at 5% or 1% level.The test is significant at the 10% and 5% level, but not at the 1% level.\n\nConsider these true- or false statements:\nIf a two-tailed p-value is .0567 then the test is significant at the 10% level but not at the 5% level. \nTRUE\nFALSE\nIf a two-tailed test is significant at the 5% level but not at the 1% level, then the two-tailed p-value will be less than 0.01. \nTRUE\nFALSE\nA two-tailed p-value of 0.060 indicates that we have 6% chance that the null hypothesis is true. \nTRUE\nFALSE"
  },
  {
    "objectID": "testing.html",
    "href": "testing.html",
    "title": "5  Hypothesis Testing",
    "section": "",
    "text": "Hypothesis testing is a method of inferential statistics which allows researchers to draw conclusions about the population based on sample data. It involves formulating hypotheses, calculating test statistics, determining p-values, and drawing conclusions about the null hypothesis.\nHypothesis testing builds upon previously covered topics like sampling theory and estimation, where sample statistics are used as the best estimate of population parameters; standard errors to express the uncertainty surrounding those estimates; and probability calculus, using probability distributions - like the standard normal distribution - to compute the probability of observing certain values based on the sampling distribution.\nTo introduce the concept of hypothesis testing, let’s consider an intuitive example. Imagine your car won’t start, and you hypothesize that the battery is dead. You then perform an experiment by replacing the battery. If the car starts, you conclude that your initial hypothesis was correct - the battery was indeed dead.\nIn this thought experiment, you only need one piece of evidence. Statistical hypothesis instead rely on evidence from many observations, and use probability calculus to test hypotheses in the presence of uncertainty. Statistical tests use probability calculations to compute how probable it is to observe the sample data if the null hypothesis were true. If the resulting probability is very low, we may doubt whether the null hypothesis is indeed true.\nThe steps involved in hypothesis testing are as follows:\n\nFormulate hypotheses: This involves stating a testable proposition about population parameters.\nCalculate a test statistic: The test statistic describes how many standard errors away from the population statistic, under the null hypothesis, the sample statistic is.\nCalculate the p-value: The p-value represents the probability of observing a value at least as extreme as the sample statistic, assuming the null hypothesis is true.\nDraw a conclusion about the null hypothesis: Based on the p-value, we either reject or fail to reject the null hypothesis.\n\nHypotheses can be formulated as equality or inequality statements. Equality hypotheses state that a value, difference, or effect is equal to zero, while inequality hypotheses state that a value, difference, or effect is larger or smaller than a specific value. It’s important to keep in mind that hypothesis testing does not provide evidence for hypotheses but rather helps in casting doubt on a null hypothesis.\nIn addition to the null hypothesis, we can also specify an alternative hypothesis. The specification of the alternative hypothesis depends on a bit of philosophy of science. Fisher’s philosophy suggests using only a null hypothesis; if this null hypothesis is rejected, the “truth” must be anything other than the null hypothesis. We could thus say that, according to Fisher’s philosophy, the alternative hypothesis is the negation of the null hypothesis. If \\(H_0: \\mu = 0\\), then \\(H_a: \\mu \\neq 0\\); or, if \\(H_0: \\mu &gt; 0\\), then \\(H_a: \\mu \\leq 0\\). The alternative hypothesis is in both cases the “opposite” of the null hypothesis.\nNeyman-Pearson’s philosophy instead involves stating specific null and alternative hypotheses, with an explicit expected effect size for the alternative hypothesis. Assuming a specific expected effect size allows us to calculate the probabilities of drawing correct or incorrect conclusions.\nIn hypothesis testing, we calculate a test statistic, which measures the distance between the hypothesized population value and the sample statistic in terms of standard errors. The probability of observing a test statistic at least as extreme as the one we did observe is computed using an appropriate probability distribution. For many tests, we use either the Z-distribution or t-distribution, depending on whether we know the population standard deviation or not. This gives us a probability value (p-value), representing the probability of observing data as extreme as or more extreme than the sample data, assuming that the null hypothesis is true.\nWhen interpreting p-values, it’s crucial to understand that they give the probability of observing certain data assuming the null hypothesis is true, rather than providing the probability of the null hypothesis being true or false. The p-value is then compared to a pre-determined significance level (usually denoted as alpha) to make a decision about accepting or rejecting the null hypothesis.\nRejecting the null hypothesis indicates that the observed data is unlikely to occur if the null hypothesis were true. On the other hand, failing to reject the null hypothesis means that the observed data is not surprising or does not provide sufficient evidence to reject it.\nWhen testing hypotheses, we can make two types of errors: A Type I error refers to rejecting the null hypothesis when it is true (a false-positive conclusion), while Type II error refers to accepting the null hypothesis when it is false (failing to detect a true effect).\n\n6 Formative Test\nA formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material.\nComplete the formative test ideally after you’ve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention\n\nQuestion 1\n\nSuppose that I ask a random sample of 5 students how many pairs of shoes they have. The number of pairs are: 7, 6, 8, 6, and 8. What is the variance of these pairs of shoes?\n\n7124\n\n\nQuestion 2\n\nSix students work on a Statistics exam. They obtain the following grades: 8, 9, 5, 6, 7 and 8. The teacher calculates a certain statistic, which is equal to 7.5. Which statistic did the teacher calculate?\n\nModeMeanStandard deviationMedian\n\n\nQuestion 3\nFor which of the three scatterplots below is the correlation coefficient largest? \nA\nB\nC\n\n\n\n{width = 30%}\n\n\n{width = 30%}\n\n\n{width = 30%}\n\n\nFigure 6.1: Question 3 scatterplots\n\n\n\nSix students work on a Statistics exam. They obtain the following grades: 8, 9, 5, 6, 7 and 8. The teacher calculates a certain statistic, which is equal to 7.5. Which statistic did the teacher calculate?\n\nModeStandard deviationMedianMean\n\n\n\n\n\nShow answers\n\nQuestion 1\nThe variance is the sum of squared distances of observations to the mean, divided by the number of observations minus one. So calculate:\n\\(S_{X}^2= \\frac{\\sum_{i=1}^nX_i}{n} = \\frac{(7 + 6 + 8 + 6 + 8)}{5} = 7\\)\nQuestion 2\nFirst rule out improbable answers; all grades are pretty close to each other, so it’s impossible for the variance to be that high. We can see what the mode (most common value) is: it’s 8. So we only choose between mean or median.\nMean: calculate \\(\\bar{X}= \\frac{\\sum_{i=1}^nX_i}{n} = \\frac{8 + 9 + 5 + 6 + 7 + 8}{6} = 7.17\\)\nMedian: order the numbers, note that there is an odd number, take the average of the two middle numbers. 5, 6, 7, 8, 8, 9 -&gt; 7.5\nQuestion 3\nCorrelation measures linear association, so eliminate option C. Option B shows a very small correlation - probably 0 or maybe .1. So the correct answer is A, which shows a moderate negative correlation."
  },
  {
    "objectID": "glm1.html",
    "href": "glm1.html",
    "title": "6  GLM-I: Linear Regression",
    "section": "",
    "text": "7 Tutorial"
  },
  {
    "objectID": "glm1.html#regression-analysis",
    "href": "glm1.html#regression-analysis",
    "title": "6  GLM-I: Linear Regression",
    "section": "\n7.1 Regression Analysis",
    "text": "7.1 Regression Analysis\nIn this assignment we will make a start with regression analysis.\nWe will go through the different steps of running and interpreting a regression analysis.\nOpen the file Work.sav to get started.\nConsider the following research question: “Does variety at work predict pleasure at work?”\nWhat is the dependent variable in this case? \nPleasure\nVariety\nTo answer the research question, we will run a linear regression analysis.\nSelect the following menu item: Analyze &gt; Regression &gt; Linear\nChoose the dependent variable (scpleasure) and independent variable (scvariety). Paste and run the syntax.\nIf you look in the output, you will see that SPSS shows four tables in the output file.\nIn the table labeled “Model Summary” we can find the R2 value. R2 indicates the total proportion of explained variance in the dependent variable in the model; this is the focus of next week’s class.\nWhat proportion of the variance Emotional pressure (scpleasure) is explained by our single predictor Variety at work (scvariety)? \nConsider the unstandardized Coefficients in the table labeled “Coefficients”.\nWhat is the value of the intercept (b0) for the regression line? \nHow should we interpret the intercept (or “constant”) within the context of this analysis?\n\nSomeone who reports zero Variety at work (meaning a score of 0 on scvariety) has an expected value of this many points on Pleasure.Everyone who reports zero Variety at work (meaning a score of 0 on scvariety) has a value of this many points on Pleasure.The sample average of Pleasure is this many pointsFor every point in Variety at work, we expect an increase of this many points in Pleasure.\n\nConsider the unstandardized regression coefficients again.\nWhat is the value of the regression coefficient of scpleasure on scemoti (b1)? \nHow should we interpret the regression coefficient of scvariety within the context of this analysis?\n\nIf someone’s score on Variety at work increases with 1 SD, their score on Pleasure increases by this many SDs.This is the sample average of PleasureIf someone’s score on Variety at work increases with 1 point, their score on Pleasure increases by this many points.This is the sample average score of Variety at work.\n\nThe “Coefficients” table also shows whether or not the effect of scvariety on scpleasure is significant.\nWhat is the p-value for the regression coefficient for scvariety? \nCan we conclude that the effect of scvariety on scpleasure is significant? (use \\(\\alpha\\) = .05). \nYes\nNo"
  },
  {
    "objectID": "glm1.html#assumptions",
    "href": "glm1.html#assumptions",
    "title": "6  GLM-I: Linear Regression",
    "section": "\n7.2 Assumptions",
    "text": "7.2 Assumptions\nRecall that regression assumes linearity, normality of residuals, homoscedasticity (equal variance of residuals), and independence of observations. We will check each of these assumptions in turn, except for independence of observations because this is a property of our sampling method and cannot be checked statistically.\n\n7.2.1 Scatterplot\nA scatter plot can provide some insight into linearity.\nTo make a scatter plot: Graphs &gt; Legacy Dialogs &gt; Scatter/Dot &gt; Simple Scatter\nPlace variety at work on the X axis and emotional pressure on the Y axis.\nIs the assumption of linearity met in this case? \nYes\nNo\n\n7.2.2 Regression Diagnostics\nAside from the scatterplot, we can check the assumptions of regression by requesting additional options in the analysis.\nGo back to the analysis dialog via Analyze –&gt; Regression –&gt; Linear. Verify that you still have the correct predictor and outcome.\nThen, click the Plots button. You want a plot of the predicted values against the residual values, so put ZPRED in the X box and ZRESID in the Y box.\nAlso check the boxes for a Histogram and normal probability plot, then hit continue.\nNow paste and run the syntax. You should see the following added to your previous regression syntax:\n  /SCATTERPLOT=(*ZRESID ,*ZPRED)\n  /RESIDUALS HISTOGRAM(ZRESID) NORMPROB(ZRESID)\n\n7.2.3 Linearity\nHow can we test linearity using this additional output?\nFirst, we can use the “Normal P-P plot”. If the relationship is perfectly linear, all dots should be on the diagonal line. If the points are deviating from the line, the relationship is not perfectly linear. Small deviations are OK; for example, the plot below shows a linear association:\n\nDoes the P-P plot for your regression give cause for concern for violation of the assumption of linearity? \nYes\nNo\nUnclear\n\n7.2.4 Normality\nOne way to check normality is by examining the histogram of residuals. This histogram displays a normal curve by default. If the observed residuals deviate strongly from this histogram, there may be a problem.\nThe plot below shows a residual histogram with some minor deviations from normality (too few scores near the mean). This is probably still fine:\n\nDoes the residual histogram for your regression give cause for concern for violation of the assumption of normal residuals? \nYes\nNo\nUnclear\n\n7.2.5 Homoscedasticity\nWe examine homoscedasticity using a plot of standardized predicted values against standardized residuals. We want residuals to be identically distributed on the Y-axis for all values on the X-axs. In other words, this scatterplot should look like a dot cloud (no pattern) around the zero line (left picture below), and not like a pattern (right picture below).\n\nDoes the scatterplot for standardized predicted values against residual values for your regression give cause for concern for violation of the assumption of homoscedasticity? \nYes\nNo\nUnclear\nWrite up a discussion of potential violations of the assumptions for your regression, then check your answer.\n\n\nExplanation\n\nWe observed that the observed scores deviated from the P-P plot in an S-shaped pattern. We further observed that, in a histogram of standardized residuals, the observed residuals were right-skewed. Finally, we observed less variance around the regression line for low scores and more variance around the regression line for high scores.\nThese findings give cause for concern of violations of the assumptions of regression. One potential explanation is that the effect might be quadratic instead of linear. (Optional)"
  },
  {
    "objectID": "data.html#ss-values-and-beliefs-about-individuals-and-collectives",
    "href": "data.html#ss-values-and-beliefs-about-individuals-and-collectives",
    "title": "Data for Portfolio",
    "section": "SS: Values and Beliefs about Individuals and Collectives",
    "text": "SS: Values and Beliefs about Individuals and Collectives\nThis synthetic dataset was inspired by Wave 7 of the World Values Survey (Haerpfer et al., 2022).\nThe World Values Survey (WVS) is a global research project that explores people’s values and beliefs and what social and political impact these have. Among topics covered are support for democracy, tolerance of ethnic minorities, support for gender equality, the role of religion and changing levels of religiosity, the impact of globalization, attitudes toward the environment, work, family, politics, national identity, culture, diversity, insecurity, and subjective well-being. This data source is used by governments, scholars, and international organizations like the United Nations.\nExamples of research questions:\n\nWhat proportion of participants considers work to be very important in life? (Q5)\nWhat proportion of participants score more extreme than 9/10 on a left-right political ideology scale? (Q240)\nIs trust in the government significantly higher than the neutral middle of the scale (3)? (Q292O)\nDoes participants’ age predict the attitude that children should take care of their parents? (Q38 and Q262)\n\nData documentation: https://www.worldvaluessurvey.org/WVSDocumentationWV7.jsp\nReference: Haerpfer, C., Inglehart, R., Moreno, A., Welzel, C., Kizilova, K., Diez-Medrano J., M. Lagos, P. Norris, E. Ponarin & B. Puranen (eds.). 2022. World Values Survey: Round Seven - Country-Pooled Datafile Version 5.0. Madrid, Spain & Vienna, Austria: JD Systems Institute & WVSA Secretariat. doi:10.14281/18241.20."
  },
  {
    "objectID": "data.html#cn-behavioral-and-neural-correlates-of-empathy-in-adolescents",
    "href": "data.html#cn-behavioral-and-neural-correlates-of-empathy-in-adolescents",
    "title": "Data for Portfolio",
    "section": "CN: Behavioral and Neural Correlates of Empathy in Adolescents",
    "text": "CN: Behavioral and Neural Correlates of Empathy in Adolescents\nThis synthetic dataset was inspired by a study by Overgaauw and colleagues (2014).\nAdolescence is characterized by significant changes in how individuals perceive and interact with others, both cognitively and emotionally. Empathy is a crucial element in appropriately responding to the emotions and actions of others. It is often described as the capacity to understand and share the emotional experiences of others, enabling us to comprehend and anticipate their intentions. Children who possess higher levels of empathy demonstrate greater emotional regulation and engage in more prosocial behavior towards others. This experimental study presented adolescents with either positive or negative social situations, and asked them to focus either on person A or person B in those situations (in negative situations, person A was the perpetrator and person B was the victim). They then measured how many coins participants were willing to give to the focal person. Empathy was measured using a scale with three sub-dimensions of empathy (Contagion, Understanding, and Support), and brain activation in several regions of interest was measured.\nReference: Overgaauw, S., Güroğlu, B., Rieffe, C., & Crone, E. A. (2014). Developmental Neuroscience, 36 (3-4). Behavior and Neural Correlates of Empathy in Adolescents. https://doi.org/10.1159/000363318"
  },
  {
    "objectID": "data.html#be-sustainable-food-choices",
    "href": "data.html#be-sustainable-food-choices",
    "title": "Data for Portfolio",
    "section": "BE: Sustainable Food Choices",
    "text": "BE: Sustainable Food Choices\nThis synthetic dataset was inspired by a study by De Boer and colleagues (2007).\nSustainability goals may require people in Western countries to reduce their meat consumption. This study investigated which values motivate sustainable food choices related to meat consumption. The researchers surveyed 1530 Dutch consumers and found that various human values were related to different food choice motives. Universalism, in particular, had a unique impact on food choices that favored reduced meat, or free-range meat consumption. This study provided insight into the way values, motives and attitudes influencing sustainable food choices and shape individuals’ dietary decisions.\nReference: Joop de Boer; Carolien T. Hoogland; Jan J. Boersema (2007). Towards more sustainable food choices: Value priorities and motivational orientations. Food Quality and Preference, 18(7), 0–996. doi:10.1016/j.foodqual.2007.04.002."
  }
]