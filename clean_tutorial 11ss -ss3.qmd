# Lab 1: Introduction

```{r, include = FALSE}
source("R/booktem_setup.R")
source("R/my_setup.R")
```

## PCA


Open the data file: emotions.sav.


The data file consists of data from the International College Survey 2001 (Diener and colleagues, 2001). In this survey, data on emotions was collected for 41 countries. The data you’ll analyze in this assignment is about norms for experiencing/expressing 12 emotions in Belgium.

<!-- The questionnaire the participants filled out looked like this: -->

<!-- ![](images/Figure10.png) -->


Let’s look at the data. The first two columns contain the number of the participant and the nation, so you don’t need to include them in the analysis.

True or false: There are missing data. `r torf(TRUE)`

Suppose we are only interested in reducing the number of dimensions of the data, which method would you use? `r mcq(c(answer = "Principal Component Analysis", "Explanatory Factor Analysis", "Confirmatory Factor Analysis", "Path Analysis")[sample.int(4)])` 
 

Navigate to Analyze → Dimension Reduction → Factor in SPSS

In the tab Extraction: choose the correct method.

Also enable the option Scree plot and specify which variables need to be included in the analysis.

Check the Options tab. Can you determine what method is used to deal with missing data?

`r longmcq(c(answer = "All cases with missing values are removed prior to analysis", "All missing values are removed prior to analysis", "All correlations are computed based on available data for that pair of variables", "No action is taken")[sample.int(4)])`

Paste the syntax and run the analysis.

Take a look at the output.

What number of component have an Eigenvalue greater than 1 (Kaiser's criterion)? `r fitb(3, num = T)`

How many components does the scree plot suggest?

`r fitb(2, num = T)`

Redo the analysis with the number of components you need to retain according to the scree plot.

You can specify the number of components in the Extraction menu of the Factor Analysis window.

Click Fixed number of factors and enter the number of components (2).

Run the analysis and look at the loadings in the Component matrix.

True or false: This solution is easy to interpret. `r torf(FALSE)`

The two principal components seem to correspond with positive emotions (appropriate and valued), and negative emotions (inappropriate and not valued), but there is not enough simple structure (too many variables have a high loading on both components).

To aid interpretation, you could rotate the solution. Considering the assumptions of both, would you choose an orthogonal or oblique rotation? `r mcq(c("orthogonal", answer = "oblique"))`

`r hide("Answer")`
It is unlikely that positive and negative emotions are uncorrelated! An oblique rotation seems by far the most sensible choice. 

`r unhide()`

Regardless of your previous answer, redo the analysis and choose Direct Oblimin in the Rotation menu.


Take a look at the component loadings in the Pattern matrix.

Which component would you label Positive Emotions? Number.. `r fitb(2, num = T)`

Compare the component loadings in the Pattern Matrix with the loadings in the Component Matrix.

We now observe that the loadings resemble a simple structure more closely than before the rotation: the low loadings are lower and the high loadings are higher.

Note: Due to the oblique rotation, the loadings are no longer equal to item-component correlations.


The ratings for expressing negative emotions are summarized in rotated component 1 and the ratings for expressing positive emotions are summarized in rotated component 2.

What is the correlation between these two rotated components? `r fitb(0.143, num = T, tol = .01)`


Redo the Principal Component Analysis again one last time to save the component scores in the data set. Open Scores in the Factor Analysis window, check the Save as variables checkbox. Have a look at these component scores (now added to your data set): these are the scores for each person on the two components.

Alternatively, add this syntax:

```
  /SAVE REG(ALL)
```

What is the component score for the first person on the first component? `r fitb(1.937, num = T, tol = .01)`

Take a look at the table Total Variance Explained.

How much of the variance do the two components together account for? `r fitb(51.575, num = T, tol = .1)`%


What proportion of the variance in the item stress is accounted for by the two components? `r fitb(0.505, num = T, tol = .01)`

Which item has the highest unicity? `r mcq(c(answer = "Pride", "Cheerful", "Anger", "Happy")[sample.int(4)])` 

## Factor Analysis (a)

We will move on to work with Exploratory Factor Analysis.

For this second assignment you will perform an Exploratory Factor Analysis (EFA) in SPSS on a set of 18 items. These items measure Tolerance and are part of the European Value Survey (EVS).

 
Discuss with your group when we decide to use Exploratory Factor Analysis and when we decide to use Principal Component Analysis.

`r hide("Explanation")`
PCA is a data reduction technique. We use it when we want to summarize information in the items.

EFA is used to identify latent variables underlying the measured items. EFA is typically used when a questionnaire has not been validated yet. When we use EFA, we usually do not know exactly which item belongs to which dimension (although we might have an idea based on our theory).

`r unhide()`
 

When do we use Confirmatory Factor Analysis?

`r hide("Explanation")`
CFA is used when we DO know which items belong to which dimension. With CFA we can then check whether the model that we have in mind corresponds with what we see in the data.
 

`r unhide()`

<!-- The Tolerance questionnaire is displayed in the figure below. -->

<!-- Take a few minutes to read the items carefully. -->

<!-- ![](images/Figure11.png) -->

 

Open the file evs.sav in SPSS.



<!-- To check whether we are allowed to carry out factor analysis and to know how many factors we should select, we first run another quick PCA. -->

Select Factor via Analyze -> Dimension Reduction.

Use the extraction method appropriate for EFA.

Drag all items of the tolerance scale into the ‘items’ window.
Go to Descriptives and select the options “Coefficients” and “KMO and Bartlett’s test of sphericity”.
Then, go to extraction and select “unrotated factor solution” and “scree plot”.
Paste and run the syntax.

The factorability, as determined by the KMO index, is `r mcq(c(answer = "Marvelous", "Middling", "Mediocre")[sample.int(3)])`

How many factors would you want to select based on the scree plot? `r fitb(2, num = T)`

 
How many factors would you want to select based on Kaiser’s criterion? `r fitb(3, num = T)`

Re-do your analysis with the appropriate number of factors.

In the tab Extraction: Ask for Principal Axis Factoring and choose the number of factors you want to extract based on the scree plot.

In the tab Rotation: Tick the box Direct Oblimin.

In the tab Options: The interpretation of the pattern matrix is easier if you suppress all coefficients in that table that are small (or low as we call it, so values < 0.30). To do so, click on options and ask SPSS to suppress the small coefficients.

In the tab Descriptives: Ask for the reproduced matrix.

Paste and run the syntax.
 

When we interpret the output of the factor analysis, we inspect 4 tables: the pattern matrix, the communalities, the factor correlation matrix, and the reproduced correlation matrix.

We will start with the pattern matrix.

Inspect the factor loadings in the pattern matrix.

Which item has the highest absolute factor loading on Factor 2? Type the variable label from the table: `r fitb("divorce")` 
 
Decide for yourself: does the factor solution follow a simple structure? Then check your answer.


`r hide("Answer")`
The solution almost follows a simple structure. Only for the item Accepting a bribe we see high factor loadings on both factors.
`r unhide()`

Inspect the communalities table.

How much of the variance in the item “suicide” do the factors explain? `r fitb(0.343, num = T, tol = .01)`

Check the correlations between the three factors.

How substantial are the correlations between the factors? `r mcq(c("small", answer = "medium", "large"))`

Inspect the residual correlations.

Which residual correlation is most concerning? 

`r longmcq(c(
"Between driving under the influence and claiming state benefits.",
answer = "Between taking soft drugs and joyriding.",
"Between speeding over the limit and smoking in public places.)[sample.int(3)])"`

Take a look at the pattern matrix again.

Can you think of a meaningful label for each of the factors? (Take into consideration whether the loadings are positive or negative). Then check your answer.

`r hide("Answer")`

There appears to be a distinction between legal and religious issues.

`r unhide()`
