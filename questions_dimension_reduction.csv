"What is the primary goal of Principal Components Analysis (PCA)?","Dimension reduction","Factor extraction","Model confirmation","Data classification","The primary goal of PCA is dimension reduction, where a small number of components are used to explain most of the variance in the items.",
"In Exploratory Factor Analysis (EFA), what is the role of latent variables?","They cause people's responses to the items","They are directly measured","They confirm pre-defined structures","They represent linear combinations of original items","In EFA, latent variables (factors) are assumed to cause people's responses to the items, unlike PCA where components represent linear combinations of original items.",
"What distinguishes Confirmatory Factor Analysis (CFA) from PCA and EFA?","It tests a hypothesized measurement model","It is used for dimension reduction","It assumes that factors cause item responses","It is an exploratory method","CFA is a confirmatory approach that tests how well a hypothesized measurement model fits the data, unlike PCA and EFA, which are exploratory.",
"How are components ordered in PCA?","Largest variance with the first component, second-largest with the second, and so on","Randomly assigns variance to components","Aligns smallest variance with the first component","Equally distributes variance across all components","PCA aligns the data such that the largest amount of variance is with the first component, and each subsequent component accounts for the next largest variance.",
"What is one way to understand PCA?","As a method of lossy compression of data","As a method for data expansion","As a technique for classification of individuals","As a process for data duplication","PCA can be understood as a way to summarize k items using fewer than k components, which can be seen as a form of lossy compression of data.",
"What is the purpose of using orthogonal rotation, like Varimax, in PCA?","To simplify the pattern of loadings and improve interpretability","To increase the correlation between items and factors","To directly interpret loadings as correlations","To reduce the number of components retained","Orthogonal rotation, such as Varimax, is employed in PCA to simplify the pattern of loadings, making them easier to interpret.",
"What distinguishes Principal Axis Factoring (PAF) from Maximum Likelihood (ML) estimation?","PAF provides a solution even in complex models or non-normal data","ML is only suitable for CFA","PAF allows for a test of model fit","ML always results in higher factor loadings","PAF is an iterative method suitable for complex models or non-normal data, whereas ML, used for both EFA and CFA, is better for data that are multivariate normal.",
"How are Eigenvalues computed differently in EFA compared to PCA?","Eigenvalues are smaller in EFA as some variance is attributed to error variance","Eigenvalues are larger in EFA","Eigenvalues are the same in both EFA and PCA","EFA does not compute Eigenvalues","In EFA, Eigenvalues are always smaller than in PCA because some variance is attributed to error variance, leading to Eigenvalues that are less than the number of indicators and sometimes negative.",
"What indicates a problem with multicollinearity in Exploratory Factor Analysis (EFA)?","A determinant value lower than 0.00001","A high Kaiser-Meyer-Olkin (KMO) statistic","A determinant value equal to 1","No presence of multicollinearity","In EFA, a determinant value lower than 0.00001 indicates excessive multicollinearity, making it difficult to discern the unique contribution of collinear items to the factor model.",
"Which of these is a method for estimating latent variable scores in EFA?","Regression method","Using mean scores of all items","Sum scores","Assigning equal weights to all items","In EFA, factor scores can be estimated using methods like the regression method or the Bartlett method, each with its own advantages and shortcomings."
