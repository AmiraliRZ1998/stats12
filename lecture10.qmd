---
title: "Lecture 10 - GLM VI\nNested models"
author:   "Caspar J. van Lissa"
date:     "`r format(Sys.Date(), '%d %b %Y')`"
format: revealjs
#server: shiny
---

```{r}
library(kableExtra)
require(gridExtra)
library(tidySEM)
library(scales)
library(eulerr)
source("functions.r")
options(knitr.kable.NA = '')

invdat <- matrix(c(1, .3, .24,
                   .3, 1, .5,
                   .24, .5, 1), nrow = 3, ncol = 3, byrow = TRUE)
set.seed(76)
invdat <- data.frame(mvtnorm::rmvnorm(60, sigma = invdat))

names(invdat) <- c("Work_hours", "Gender_role", "Involvement")

invdat$Work_hours <- rescale(invdat$Work_hours, to = c(0,40))
invdat$Gender_role <- rescale(invdat$Gender_role, to = c(1,7))
invdat$Involvement <- rescale(invdat$Involvement, to = c(0,50))

m_both <- lm(Involvement ~ Work_hours + Gender_role, invdat)

m_work <- lm(Involvement ~ Work_hours, invdat)
m_gender <- lm(Involvement ~ Gender_role, invdat)
m_both <- lm(Involvement ~ Gender_role+Work_hours, invdat)
```

# Nested models

## Definition

> **Nested models** occur whenever you can obtain a simpler model by constraining some parameters of a more complex model to 0.

Models are *nested* if they are identical, except that some parameters are constrained to 0

* All predictors in Model 1 are also in Model 2.
* Model 1 is the 'smaller' or 'constrained' model, Model 2 is the 'larger' or unconstrained model
* Model 2 always has better fit Model 1


## Example nested model

You already saw this in our first class on bivariate regression:

* 1. Null model: $\hat{Y}_i = a$, which is the same as $\hat{Y}_i = a + 0 * X_1$ (so $b_1 = 0$)
* 2. Regression model: $\hat{Y}_i = a + b_1 * X_1$


Model 1 (null model) is "nested" in model 2 (regression model)

* Model 1 is "constrained": relative to model 2, parameter $b_1$ is fixed to 0
* Model 2 is "unconstrained": relative to model 1, all parameters are free

## Example nested model

We can apply the same principle to multiple regression:

* 1. $\hat{Y}_i = a + b_1 * X_1$
* 2. $\hat{Y}_i = a + b_1 * X_1 + b_2 * X_2$

Model 1 (one predictor) is "nested" in model 2 (multiple regression)

* Model 1 is "constrained": relative to model 2, slope $b_2$ is fixed to 0
* Model 2 is "unconstrained": relative to model 1, all parameters are free

## Example {.smaller .flexbox .vcenter}

```{r, echo=FALSE, warning=FALSE, message=FALSE}
w <- summary(m_work)$coefficients[,-2]
w <- apply(w, 2, formatC, digits = 2, format = "f")
G <- summary(m_gender)$coefficients[,-2]
G <- apply(G, 2, formatC, digits = 2, format = "f")
B <- summary(m_both)$coefficients[,-2]
B <- apply(B, 2, formatC, digits = 2, format = "f")
```

**Only work hours, $R^2 `r report(summary(m_work)[["r.squared"]])`$:**

Variabele   | B           | t          | p  
------------|-------------|------------|-------------
(Intercept) | `r w[1,1]`  | `r w[1,2]` | `r w[1,3]`
Work_hours    | `r w[2,1]`  | `r w[2,2]` | `r w[2,3]`

**Only gender roles, $R^2 `r report(summary(m_gender)[["r.squared"]])`$:**

Variabele   | B           | t          | p  
------------|-------------|------------|-------------
(Intercept) | `r G[1,1]`  | `r G[1,2]` | `r G[1,3]`
Gender_roles | `r G[2,1]`  | `r G[2,2]` | `r G[2,3]`

**Multiple regression, $R^2 `r report(summary(m_both)[["r.squared"]])`$:**

Variabele   | B           | t          | p  
------------|-------------|------------|-------------
(Intercept) | `r B[1,1]`  | `r B[1,2]` | `r B[1,3]`
Work_hours    | `r B[2,1]`  | `r B[2,2]` | `r B[2,3]`
Gender_roles | `r B[3,1]`  | `r B[3,2]` | `r B[3,3]`

## Nested models

We might ask the question: Does adding gender roles to a model with only work hours significantly improve our ability to predict involvement?

* We can determine this with a nested model test


## Difference in $R^2$

```{r, echo=FALSE, warning=FALSE, message=FALSE}
W <- summary(m_work)
W <- c(W$r.squared, W$df[1:2])
W[2]<-W[2]-1
W[1] <- formatC(W[1], digits = 2, format = "f")
B <- summary(m_both)
B <- c(B$r.squared, B$df[1:2])
B[2]<-B[2]-1
B[1] <- formatC(B[1], digits = 2, format = "f")
diff <- as.numeric(B[1])-as.numeric(W[1])
compare_aov <- anova(m_work, m_both)

```

$R^2$ always increases when we add predictors:

Model                      | $R^2$     | df1      | df2  
---------------------------|-----------|----------|-------------
C: Hours                | `r W[1]`  | `r W[2]` | `r W[3]`
U: Hours and Gender roles | `r B[1]`  | `r B[2]` | `r B[3]`


\vspace{1cm}

$\Delta R^2 = R^2_u - R^2_c = `r B[1]` - `r W[1]` = `r diff`$

## {background-iframe="https://cjvanlissa.shinyapps.io/Polynomials/"}


# Incremental F-test

## Incremental F-test

$\Delta R^2 = R^2_c - R^2_u = `r B[1]` - `r W[1]` = `r diff`$

$F = \frac{(SSR_u - SSR_c) / (df1_u-df1_c)}{SSE_u / df2_u}$

We use an F-test to determine whether the increase in $R^2$ is significant:

* Increase in R-square: $\Delta R^2$
* $SSR_u - SSR_c$: increase in variance explained by the model
* $df1_u-df1_c$: increase in the number of parameters
* $df2_u$ degrees of freedom for the residuals for the unconstrained model
* Sig. F Change = p value for the F-test for R-square change!



## Compare to basic F-test {.smaller}

Remember the F-test for bivariate regression:

$$
F = \frac{SSR/(p-1)}{SSE/(n-p)}
$$

Note that this is the same as an incremental F-test comparing the null model with the regression model:

$$
F = \frac{SSR/df1_u}{SSE/df2_u} = \frac{(SSR_u - SSR_c) / (df1_u -df1_c)}{SSE_u / df2_u} = \frac{(SSR_u - 0) / (df1_u - 0)}{SSE_u / df2_u}
$$

## Putting it together

So, if you have two nested models, you could think of three comparisons:

1. $\hat{Y}_i = a$ (the null model)
2. $\hat{Y}_i = a + b_1 X_1$ (bivariate regression)
3. $\hat{Y}_i = a + b_1 X_1 + b_2X_2$ (multiple regression)

The F-test for the significance of the $R^2$ of model 2 is essentially an incremental F-test for $\Delta R^2$ between model 1 vs model 2

Then there's also an incremental F-test for $\Delta R^2$ between model 2 vs model 3

## Reporting

The model with work hours and gender role attitudes as predictors explained significantly more variance in the data than the model with only work hours, $\Delta R^2 = `r diff`, F(`r compare_aov[["Df"]][2]`, `r compare_aov[["Res.Df"]][2]` = `r round(compare_aov[["F"]][2], 2)`, p < .001)$.


## Hierarchical regression

* Add predictors in blocks
    + If you represent a categorical predictor as dummies, all dummies must be included in the same block! Together, they represent one variable.
* Each block is added to preceding ones, so these models are nested
* Conduct incremental F-tests to determine whether each additional block significantly increases $R^2$

## Why hierarchical regression? {.smaller}

To determine whether theoretically relevant factors explain significant variance *above and beyond* demographic characteristics

* E.g.: you want to predict college achievement based on high school GPA while controlling for demographic factors
    + Block 1: Demographic factors (age, sex, neighborhood quality, SES)
    + Block 2: GPA

To determine whether a previously neglected factor explains additional variance

* E.g.: you want to show that your new scale of morality explains more variance in behavioral outcomes than an existing scale of morality
    + Block 1: Add all subscales of the old morality scale
    + Block 2: Add all subscales of the new morality scale

To test the overall effect of adding dummies for a __categorical predictor__ with >2 categories
    + You need one F-test for all dummies, together; not individual t-tests
