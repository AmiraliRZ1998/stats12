{
  "hash": "0bd5f07ce8acca141bf220a8c706a7a5",
  "result": {
    "markdown": "# GLM: ANCOVA {#sec-ancova}\n\n\n\n\n\nANCOVA, which stands for Analysis of Covariance, is an extension of the concepts we've covered in bivariate linear regression and multiple regression.\nIt is essentially a multiple regression with a categorical predictor and one or more continuous predictors. What's \"special\" about this technique is that it is commonly used when the predictor of interest is that categorical variable, and the continuous predictor(s) are so-called \"covariates\": predictors that are only included to improve our estimate of the effect of the categorical predictor of interest.\n\nYou will often see this technique used to analyze data from experiments or \"natural experiments\", where participants self-select into a treatment group.\n\nWhile ANCOVA is a useful technique, it comes with some serious pitfalls: any time control variables are used, we are making assumptions about causality. If these assumptions are incorrect, our estimates of the effect of interest will be (severely) biased.\n\n## Covariates and Their Role\n\nCovariates are variables that have a relationship with the dependent variable but are not the primary focus of the study. They are often referred to as control variables, as they help control for unwanted variability and improve the precision of the analysis. Examples of common covariates include age, gender, education level, or any other variables that might influence the dependent variable.\n\nIn terms of causality, it's crucial to consider the relationships between covariates, predictors, and the outcome variable. Control variables should ideally be confounders – variables that influence both the predictor of interest and the outcome. It's essential to avoid controlling for colliders, which are variables *caused by* both the predictor and the outcome. A thorough understanding of causal relationships is crucial for proper interpretation.\n\nOne reason why researchers use control variables in ANCOVA is because they reduce the residual variance in the outcome variable, which in turn increases the power to detect the effect of the predictor of interest. Another reason to use covariates is when the goal is making causal inferences, especially in quasi-experimental designs. The proper selection of covariates that enable causal inference requires careful consideration and is beyond the scope of this course.\n\n## Good, Neutral, and Bad Controls\n\nCovariates fall into different categories based on their relationship with the predictor of interest and the outcome. An example of a good control is a confounder: a variable that causes both the predictor and the outcome. These need to be controlled to avoid spurious relationships. An example of a neutral control is a covariate that is unrelated to the predictor but can reduce error variance in the outcome, thereby increasing statistical power. Bad controls, on the other hand, can introduce biases, such as collider bias (controlling for an outcome of predictor and outcome), case control bias (controlling for an outcome of the outcome), or overcontrol bias (controlling for a mediator of the effect of the focal predictor on the outcome).\n\nOne crucial insight is that in randomized controlled experiments, the random assignment of participants to different groups breaks the relationship between confounders and the treatment variable. This makes control variables related to the confounders unnecessary. Controlling for them could even introduce bias into the analysis.\n\n\n## Calculating Adjusted Means\n\nAdjusting for covariates involves calculating adjusted means – the means that groups would have had if they scored equally on the covariate. There are two ways to mathematically calculate the adjusted means. One way is to fill in the regression equation for the desired value of the covariate. \n\nThe other way is to calculate the adjusted means from the group means:\n\n$$\n\\bar{Y}_g^{adj} = \\bar{Y}_g - b(\\bar{X}_g-\\bar{X})\n$$\n\nWhere:\n\n* $\\bar{Y}_g^{adj}$: Adjusted mean of the outcome for group g\n* $\\bar{Y}_g$: Unadjusted mean of the outcome for group g\n* $b$: Regression coefficient of the covariate\n* $\\bar{X}_g$: Group mean of covariate X\n* $\\bar{X}$: Overall mean of covariate X\n\n\nIn sum, ANCOVA is a different name for regression with a categorical predictor of interest, and continuous predictor(s) that are included to improve our estimate of the effect of the predictor of interest. ANCOVA can enhance statistical power and help make more accurate (potentiall causal) inferences. However, the careful selection of covariates and an understanding of causal relationships are paramount to its proper implementation and interpretation.\n\n# Lecture\n\n\n{{< video https://www.youtube.com/embed/MewqUBfQYok >}}\n\n\n\n\n# Formative Test\n\nA formative test helps you assess your progress in the course, and helps you address any blind spots in your understanding of the material. If you get a question wrong, you will receive a hint on how to improve your understanding of the material.\n\nComplete the formative test ideally after you’ve seen the lecture, but before the lecture meeting in which we can discuss any topics that need more attention\n\n\n::: {.cell layout-align=\"center\"}\n::: {.webex-check .webex-box}\n\n**Question 1**\n\nWhat is a valid reason for using covariates in ANCOVA? <div class='webex-radiogroup' id='radio_QAGKAYLALC'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QAGKAYLALC\" value=\"\"></input> <span>To increase the total variance</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QAGKAYLALC\" value=\"\"></input> <span>To create more complex models</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QAGKAYLALC\" value=\"answer\"></input> <span>To increase statistical power</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_QAGKAYLALC\" value=\"\"></input> <span>To replace categorical predictors</span></label></div>\n\n\n**Question 2**\n\nWhat is an example of a 'good control' variable in ANCOVA? <div class='webex-radiogroup' id='radio_YMUFQYRQMX'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YMUFQYRQMX\" value=\"\"></input> <span>A variable unrelated to the predictor</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YMUFQYRQMX\" value=\"\"></input> <span>A variable affected by the outcome</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YMUFQYRQMX\" value=\"answer\"></input> <span>A confounder</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_YMUFQYRQMX\" value=\"\"></input> <span>A variable related to the predictor</span></label></div>\n\n\n**Question 3**\n\nWhich of the following is an example of a 'bad control' variable in ANCOVA? <div class='webex-radiogroup' id='radio_TPZTXMPVMS'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TPZTXMPVMS\" value=\"\"></input> <span>A variable that causes the predictor</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TPZTXMPVMS\" value=\"\"></input> <span>A confounder</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TPZTXMPVMS\" value=\"\"></input> <span>A variable unrelated to the predictor or outcome</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_TPZTXMPVMS\" value=\"answer\"></input> <span>A variable affected by the outcome</span></label></div>\n\n\n**Question 4**\n\nIn a randomized controlled experiment, are there benefits to controling for any observed differences between the two experimental groups? <div class='webex-radiogroup' id='radio_KZEXOZNUXL'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KZEXOZNUXL\" value=\"\"></input> <span>Only if the covariates are significantly related to the predictor</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KZEXOZNUXL\" value=\"\"></input> <span>Yes, controlling for relevant covariates is essential</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KZEXOZNUXL\" value=\"answer\"></input> <span>No, random assignment breaks the predictor&apos;s relationships with confounders</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_KZEXOZNUXL\" value=\"\"></input> <span>Only if the covariates are significantly related to the outcome</span></label></div>\n\n\n**Question 5**\n\nWhat is the purpose of calculating adjusted means in ANCOVA? <div class='webex-radiogroup' id='radio_PLSPFUMLPW'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PLSPFUMLPW\" value=\"\"></input> <span>To improve the model&apos;s fit</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PLSPFUMLPW\" value=\"answer\"></input> <span>To account for covariate effects</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PLSPFUMLPW\" value=\"\"></input> <span>To create new variables</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_PLSPFUMLPW\" value=\"\"></input> <span>To replace the original means</span></label></div>\n\n\n**Question 6**\n\nWhich of the following is a key factor in choosing appropriate covariates for ANCOVA? <div class='webex-radiogroup' id='radio_AZOLASIWRI'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AZOLASIWRI\" value=\"\"></input> <span>Covariates with the highest correlations</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AZOLASIWRI\" value=\"\"></input> <span>Number of covariates</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AZOLASIWRI\" value=\"\"></input> <span>Covariates with the smallest p-values</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_AZOLASIWRI\" value=\"answer\"></input> <span>Causal relationships</span></label></div>\n\n\n**Question 7**\n\nWhat is the distinguishing feature of ANCOVA relative to multiple regression? <div class='webex-radiogroup' id='radio_ENFBAWRRCH'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ENFBAWRRCH\" value=\"\"></input> <span>Multiple regression includes only continuous predictors</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ENFBAWRRCH\" value=\"\"></input> <span>ANCOVA controls for confounding variables</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ENFBAWRRCH\" value=\"\"></input> <span>Multiple regression includes only covariates</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_ENFBAWRRCH\" value=\"answer\"></input> <span>ANCOVA always includes a categorical predictor and control variable(s)</span></label></div>\n\n\n**Question 8**\n\nIn which of these situations should you avoid controlling a particular covariate in ANCOVA? <div class='webex-radiogroup' id='radio_WAUKPTZLGW'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WAUKPTZLGW\" value=\"answer\"></input> <span>When the covariate is a mediator</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WAUKPTZLGW\" value=\"\"></input> <span>When the covariate is perfectly correlated with another covariate</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WAUKPTZLGW\" value=\"\"></input> <span>When the covariate is a confounder</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_WAUKPTZLGW\" value=\"\"></input> <span>When the covariate is irrelevant</span></label></div>\n\n\n**Question 9**\n\nAn ANCOVA model compares statistics grades for two classes of students, controlling for number of hours studied per week. The regression model is $\\text{Grade} = -1.27 + 0.50*D_{class2} + .30*Hours$. The unadjusted mean grades are 5.2 for class 1 and 7.3 for class 2. The mean hours studied were 21.56 for class 1 and 30.23 for class 2. The overall mean hours studied was 25.90. What are the adjusted means? <div class='webex-radiogroup' id='radio_BHTHVFPACF'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BHTHVFPACF\" value=\"\"></input> <span>9.35 and 2.97</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BHTHVFPACF\" value=\"\"></input> <span>-1.27 and -1.77</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_BHTHVFPACF\" value=\"answer\"></input> <span>6.50 and 6.00</span></label></div>\n\n\n:::\n\n\n<div class='webex-solution'><button>Show explanations</button>\n**Question 1**\n\nCovariates can be used in ANCOVA to reduce error variance caused by factors other than the predictor of interest.\n\n**Question 2**\n\nA confounder is a 'good control' variable in ANCOVA – a variable that influences both the predictor of interest and the outcome.\n\n**Question 3**\n\nA variable that is affected by the outcome is a 'bad control' variable in ANCOVA and can introduce biases.\n\n**Question 4**\n\n In a randomized controlled experiment, random assignment breaks the relationships between confounders and the treatment. Therefore, controlling for covariates related to the predictor is unnecessary.\n\n**Question 5**\n\nAdjusted means in ANCOVA are controlled for the effects of covariates, allowing us to understand how groups would differ on the outcome variable if they had equal scores on the covariate.\n\n**Question 6**\n\nCausal relationships are crucial when selecting covariates for ANCOVA. It's important to choose covariates that are related to the outcome and predictor in a meaningful way.\n\n**Question 7**\n\nANCOVA is one example of the broader category of models known as multiple regression; it is characterized by having a categorical predictor of interest and (continuous) covariates.\n\n**Question 8**\n\nAvoid controlling for covariates that are mediators, as controlling for mediators could lead to overcontrol bias and distort the relationships between the predictor and outcome.\n\n**Question 9**\n\n Use the formula $\\bar{Y}_g^{adj} = \\bar{Y}_g - b(\\bar{X}_g-\\bar{X})$\n\n\n</div>\n:::\n\n\n# Tutorial\n\n## Bivariate Regression (RECAP)\n\nResearchers are interested in the relationship between age and depression.\n\nThey hypothesized that older people are more vulnerable to depressive thoughts than younger people.\n\nTo test their research hypothesis, they collected data in a random sample of 164 persons from the general population. Open the dataset `HADShealthyGroup.sav`.\n\nRun a linear regression analysis using age as the independent variable and depression as the dependent variable.\n\nProceed as follows:\n\nNavigate to Analyze > Regression > Linear\n\nSelect the correct dependent and independent variable.\n\nPaste and run the syntax.\n \nHow much of the total variance in Depression is explained by Age? <input class='webex-solveme nospaces' data-tol='0.005' size='4' data-answer='[\"0.02\",\".02\"]'/>\n\nWhat can you say about the effect size? Would you say it’s a lot?\n\n\n<div class='webex-solution'><button>Answer</button>\n\nTo me, 2% of explained variance does not seem like a lot. There are probably better predictors of depression (i.e., predictors that explain more of the variance in depression).\n\n\n</div>\n\n\nTrue or false: The explained variance is significant at the 10% level. <select class='webex-select'><option value='blank'></option><option value=''>TRUE</option><option value='answer'>FALSE</option></select> \n\n\n<div class='webex-solution'><button>Answer</button>\n\nTo conclude anything about the significance of the proportion explain variance of this model, we can look at the ANOVA table or ask SPSS to show the R2-change. This shows us that the explained variance in this model is not significant compared to an empty model (i.e. including no predictors), F(1,140) = 2.836, p = .094.\n \n\n\n</div>\n\n\nWrite down the estimated regression line using the unstandardized coefficients.\n\n$Y^{'} = <input class='webex-solveme nospaces' data-tol='0.01' size='4' data-answer='[\"1.89\"]'/> + <input class='webex-solveme nospaces' data-tol='0.005' size='4' data-answer='[\"0.02\",\".02\"]'/>*\\text{age}$\n\nHow can we interpret the constant?\n\n<div class='webex-radiogroup' id='radio_MCHFPZSTRO'><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MCHFPZSTRO\" value=\"\"></input> <span>The predicted level of depression for the average age.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MCHFPZSTRO\" value=\"\"></input> <span>The average level of depression.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MCHFPZSTRO\" value=\"\"></input> <span>The average age in the sample.</span></label><label><input type=\"radio\" autocomplete=\"off\" name=\"radio_MCHFPZSTRO\" value=\"answer\"></input> <span>The predicted level of depression when age would be 0.</span></label></div>\n\n\nConsult the table with the coefficients again\n\nTrue or false: We can conclude from this table that the effect of age is significant at the 10% level. <select class='webex-select'><option value='blank'></option><option value='answer'>TRUE</option><option value=''>FALSE</option></select>\n\n\n<div class='webex-solution'><button>Answer</button>\n\nTo conclude whether the effect of Age on Depression is significant, we look at the t-test for the estimated coefficient.\n\nWe should conclude that the effect of Age on Depression is significant when using α=.10, t(140) = 1.684, p = .094.\n\n</div>\n\n\nOne of the assumptions of bivariate regression analysis is that the relationship between the independent and dependent variable is linear.\n\nState in your own words what this assumption entails.\n\n\n<div class='webex-solution'><button>Answer</button>\n\nThe assumption of a linear relationship entails that the relationship between the variables can be described with a straight line.\n\n\n</div>\n\n\n \nHow would you evaluate the assumption of linearity graphically? Do it for the data at hand.\n\nTrue or false: The relationship is linear. <select class='webex-select'><option value='blank'></option><option value=''>TRUE</option><option value='answer'>FALSE</option></select>\n\nIf the assumption is not met, speculate about other possible relationships between age and depression.\n\n\n<div class='webex-solution'><button>Answer</button>\n\nThe scatter plot does not have the shape of a cigar, so it does not unambiguously suggest a linear relationship. Thus, you may doubt whether the relationship between age and depression is best described by a linear model.\nPerhaps the relationship is quadratic. Especially persons in middle ages may be vulnerable to depressive thoughts.\nNext to the plot, you find both the estimated linear trend and a non-linear trend. It seems that the quadratic curve fits better with the data. Moreover, the quadratic model explains 6% of the variance, whereas the linear model only 2%.\n\n</div>\n\n\nRun a regression analysis using Age as the independent variable and Anxiety as the dependent variable.\n\nSummarize the results.\n\nInclude in your answer the proportion of explained variance (R-square), a description of the effect based on the estimated regression coefficients, and evaluate the significance of the effect of age on anxiety.\n\n\n<div class='webex-solution'><button>Answer</button>\n\nThe proportion explained variance in Anxiety by Age is .071. The explained variance in this model is not significant compared to an empty model (i.e. including no predictors), F(1,140) = 0.710, p = .401.\n\nThe effect is Age on Anxiety is negative (β = -0.013), meaning that anxiety decreases with age.\nHowever, the effect of Age on Anxiety is not significant when using α=.05, t(140) = -0.842, p = .401.\n\n</div>\n\n",
    "supporting": [
      "ancova_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}